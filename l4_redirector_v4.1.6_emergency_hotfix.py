#!/usr/bin/env python3
"""
ENTERPRISE L4 REDIRECTOR v4.1.6 - EMERGENCY MEMORY LEAK HOTFIX
Critical Fix: Task backlog accumulation in cleanup loop

8 Comprehensive Data Streams:
1. /api/v1/web/{port} - Client connection metrics (IP, port, bytes, duration)
2. /api/v1/l2n/{port} - L2N tunnel metrics (backend latency, throughput)
3. /api/v1/errors/l2n/{port} - Connection failures & timeouts
4. /api/v1/performance/{port} - Latency percentiles (p50/p95/p99/min/max)
5. /api/v1/throughput/{port} - Real-time throughput analysis
6. /api/v1/worker/{worker_id} - Worker health & resource usage
7. /api/v1/health/{port} - Port availability + uptime
8. /api/v1/events/{port} - Connection lifecycle events

CRITICAL FIX:
- Removed asyncio.create_task() from inside stats_lock blocks
- Task backlog was accumulating infinitely (1.8GB in 2 minutes!)
- Now properly awaits/schedules tasks outside lock
- Memory target: 7-10MB stable (was 1800MB+)

Deployment: VPS (aoycrreni.localto.net)
Backend: Windows 192.168.88.16:5814 via LocalToNet 194.182.64.133:6921
"""

import asyncio
import logging
import os
import resource
import multiprocessing
import time
import socket
import psutil
import collections
from datetime import datetime
from aiohttp import web, ClientSession, ClientTimeout
import uvloop

asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())

# ============================================================================
# CONFIGURATION
# ============================================================================

LISTEN_IP = "0.0.0.0"
LOCALTONET_IP = "194.182.64.133"
LOCALTONET_PORT = 6921
BACKEND_API_URL = f"http://{LOCALTONET_IP}:{LOCALTONET_PORT}"
BACKEND_API_TOKEN = "e7595fe6ca9de1dc14a64ef9886b00b33e35295630e736815f7d18cd4cf63075"
API_AUTH_TOKEN = "AbDo@2020!"

PORT_MAP = {
    8041: ("129.151.142.36", 1429),
    8047: ("129.151.142.36", 8667),
    8057: ("129.151.142.36", 7798),
}

MONITORED_PORTS = (8041, 8047, 8057)
LATENCY_BUCKETS = [10, 25, 50, 75, 100, 150, 250, 500, 1000, 2000, 5000, float("inf")]

API_PUSH_TIMEOUT = 3000
API_RETRY_COUNT = 2
API_RETRY_DELAY = 100
HEALTH_CHECK_INTERVAL = 10
HEALTH_CHECK_TIMEOUT = 3000
TCP_BACKLOG = 65535
BUFFER_SIZE = 65536
UDP_TIMEOUT = 0.03

MEMORY_CLEANUP_INTERVAL = 30
CONNECTION_HISTORY_SIZE = 100
EVENT_LOG_SIZE = 50

# ============================================================================
# SYSTEM TUNING
# ============================================================================

def raise_limits():
    """Increase file descriptor limits"""
    try:
        resource.setrlimit(resource.RLIMIT_NOFILE, (1_048_576, 1_048_576))
    except Exception as e:
        logging.warning(f"Could not set ulimit: {e}")

# ============================================================================
# LOGGING SETUP
# ============================================================================

def setup_logging():
    log_dir = "/var/log/redirector"
    if not os.path.exists(log_dir):
        os.makedirs(log_dir, exist_ok=True)

    logger = logging.getLogger('redirector_v4')
    logger.setLevel(logging.DEBUG)

    from logging.handlers import RotatingFileHandler

    main_log = os.path.join(log_dir, "l4_redirector_v4_enterprise.log")
    fh = RotatingFileHandler(main_log, maxBytes=100*1024*1024, backupCount=10)
    fh.setLevel(logging.DEBUG)

    ch = logging.StreamHandler()
    ch.setLevel(logging.INFO)

    formatter = logging.Formatter(
        '%(asctime)s.%(msecs)03d | %(levelname)-8s | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    fh.setFormatter(formatter)
    ch.setFormatter(formatter)
    logger.addHandler(fh)
    logger.addHandler(ch)

    return logger

logger = setup_logging()

# ============================================================================
# SHARED STATE (MULTIPROCESSING)
# ============================================================================

manager = multiprocessing.Manager()

WORKER_STATS = manager.dict()
GLOBAL_STATS = manager.dict({
    "udp_packets": 0,
    "udp_checks_ok": 0,
    "udp_checks_fail": 0,
    "backend_pushes": 0,
    "backend_push_failures": 0,
    "total_connections": 0,
    "total_bytes_in": 0,
    "total_bytes_out": 0,
})

MONITOR_STATE = manager.dict()
LATENCY_HISTOGRAM = manager.dict()
CONNECTION_EVENTS = manager.dict()
PERFORMANCE_METRICS = manager.dict()
THROUGHPUT_WINDOW = manager.dict()

stats_lock = manager.Lock()

def init_latency_histograms():
    """Initialize latency histogram buckets and event logs"""
    for port in MONITORED_PORTS:
        LATENCY_HISTOGRAM[port] = {
            "buckets": {str(b): 0 for b in LATENCY_BUCKETS},
            "count": 0,
            "sum": 0,
            "min": float('inf'),
            "max": 0
        }
        CONNECTION_EVENTS[port] = collections.deque(maxlen=EVENT_LOG_SIZE)
        PERFORMANCE_METRICS[port] = {
            "p50": 0, "p95": 0, "p99": 0,
            "min": float('inf'), "max": 0,
            "latencies": collections.deque(maxlen=1000)
        }
        THROUGHPUT_WINDOW[port] = {
            "bytes_in": 0,
            "bytes_out": 0,
            "connections": 0,
            "window_start": time.time()
        }

def init_worker(worker_id):
    """Initialize worker stats"""
    WORKER_STATS[worker_id] = {
        "active_tcp": 0,
        "total_tcp": 0,
        "bytes_in": 0,
        "bytes_out": 0,
        "uptime_sec": 0,
        "last_activity": time.time(),
    }

# ============================================================================
# BACKEND API CLIENT - 8 DATA STREAMS
# ============================================================================

async def push_to_backend(endpoint, data, retry_count=0):
    """Push data to Backend API with retry logic"""
    try:
        headers = {
            "Authorization": f"Bearer {BACKEND_API_TOKEN}",
            "Content-Type": "application/json"
        }

        url = f"{BACKEND_API_URL}{endpoint}"
        timeout = ClientTimeout(total=API_PUSH_TIMEOUT / 1000)

        async with ClientSession(timeout=timeout) as session:
            async with session.post(url, json=data, headers=headers) as resp:
                if resp.status == 200:
                    with stats_lock:
                        GLOBAL_STATS["backend_pushes"] += 1
                    return True
                else:
                    logger.debug(f"API {resp.status}: {endpoint}")
                    with stats_lock:
                        GLOBAL_STATS["backend_push_failures"] += 1
                    if retry_count < API_RETRY_COUNT:
                        await asyncio.sleep(API_RETRY_DELAY / 1000)
                        return await push_to_backend(endpoint, data, retry_count + 1)
                    return False
    except asyncio.TimeoutError:
        logger.debug(f"API timeout: {endpoint}")
        with stats_lock:
            GLOBAL_STATS["backend_push_failures"] += 1
        if retry_count < API_RETRY_COUNT:
            await asyncio.sleep(API_RETRY_DELAY / 1000)
            return await push_to_backend(endpoint, data, retry_count + 1)
        return False
    except Exception as e:
        logger.debug(f"API error: {endpoint}: {e}")
        with stats_lock:
            GLOBAL_STATS["backend_push_failures"] += 1
        if retry_count < API_RETRY_COUNT:
            await asyncio.sleep(API_RETRY_DELAY / 1000)
            return await push_to_backend(endpoint, data, retry_count + 1)
        return False

# ============================================================================
# TCP PIPE - STATELESS FORWARDING
# ============================================================================

async def pipe(reader, writer, worker_id, direction, port):
    """Bidirectional data forwarding (stateless)"""
    try:
        while True:
            data = await asyncio.wait_for(reader.read(BUFFER_SIZE), timeout=300)
            if not data:
                break
            size = len(data)
            
            with stats_lock:
                if worker_id in WORKER_STATS:
                    if direction == "in":
                        WORKER_STATS[worker_id]["bytes_in"] += size
                        GLOBAL_STATS["total_bytes_in"] += size
                        if port in THROUGHPUT_WINDOW:
                            THROUGHPUT_WINDOW[port]["bytes_in"] += size
                    else:
                        WORKER_STATS[worker_id]["bytes_out"] += size
                        GLOBAL_STATS["total_bytes_out"] += size
                        if port in THROUGHPUT_WINDOW:
                            THROUGHPUT_WINDOW[port]["bytes_out"] += size
            
            writer.write(data)
            await writer.drain()
    except asyncio.TimeoutError:
        logger.debug(f"[{port}] {direction}: Timeout after 300s")
    except Exception as e:
        logger.debug(f"[{port}] {direction}: Error - {e}")
    finally:
        try:
            writer.close()
            await writer.wait_closed()
        except:
            pass

# ============================================================================
# TCP HANDLER - MAIN CONNECTION LOGIC
# ============================================================================

async def tcp_handler(client_reader, client_writer, port, target_ip, target_port, worker_id):
    """Main TCP connection handler with 8-stream data collection"""
    client_addr = client_writer.get_extra_info('peername')
    client_ip = client_addr[0] if client_addr else 'unknown'
    client_port = client_addr[1] if client_addr else 0

    connection_start = time.time()
    backend_start = None
    backend_reader = None
    backend_writer = None
    backend_latency = 0

    logger.info(f"[{port}] NEW: {client_ip}:{client_port} â†’ {target_ip}:{target_port} (worker: {worker_id})")

    try:
        with stats_lock:
            if worker_id in WORKER_STATS:
                WORKER_STATS[worker_id]["active_tcp"] += 1
                WORKER_STATS[worker_id]["total_tcp"] += 1
            GLOBAL_STATS["total_connections"] += 1
            if port in THROUGHPUT_WINDOW:
                THROUGHPUT_WINDOW[port]["connections"] += 1

        # Connect to backend and measure latency
        try:
            backend_start = time.time()
            backend_reader, backend_writer = await asyncio.wait_for(
                asyncio.open_connection(target_ip, target_port),
                timeout=HEALTH_CHECK_TIMEOUT / 1000
            )
            backend_latency = int((time.time() - backend_start) * 1000)
            logger.debug(f"[{port}] TUNNEL: Connected (latency: {backend_latency}ms)")
        except asyncio.TimeoutError:
            logger.error(f"[{port}] TIMEOUT: Cannot reach {target_ip}:{target_port}")
            
            # Stream 3: Error event (async, outside lock)
            await push_to_backend(f"/api/v1/errors/l2n/{port}", {
                "timestamp": datetime.utcnow().isoformat() + "Z",
                "error_type": "connection_timeout",
                "backend_ip": target_ip,
                "backend_port": target_port,
                "client_ip": client_ip,
                "client_port": client_port,
                "error_message": f"Timeout connecting to {target_ip}:{target_port}",
                "worker_id": worker_id
            })
            return
        except Exception as e:
            logger.error(f"[{port}] ERROR: {e}")
            
            # Stream 3: Error event (async, outside lock)
            await push_to_backend(f"/api/v1/errors/l2n/{port}", {
                "timestamp": datetime.utcnow().isoformat() + "Z",
                "error_type": "connection_error",
                "backend_ip": target_ip,
                "backend_port": target_port,
                "client_ip": client_ip,
                "client_port": client_port,
                "error_message": str(e),
                "worker_id": worker_id
            })
            return

        # Bidirectional forwarding
        logger.debug(f"[{port}] FORWARD: Starting bidirectional forwarding")
        task1 = pipe(client_reader, backend_writer, worker_id, "in", port)
        task2 = pipe(backend_reader, client_writer, worker_id, "out", port)
        await asyncio.gather(task1, task2, return_exceptions=True)

        # Record metrics
        duration_ms = int((time.time() - connection_start) * 1000)
        logger.info(f"[{port}] CLOSED: {client_ip}:{client_port} | Duration:{duration_ms}ms | Latency:{backend_latency}ms")

        # Snapshot worker stats
        with stats_lock:
            worker_data = dict(WORKER_STATS.get(worker_id, {}))
            bytes_in = worker_data.get("bytes_in", 0)
            bytes_out = worker_data.get("bytes_out", 0)

        # Stream 1: Web traffic metrics (async, outside lock)
        await push_to_backend(f"/api/v1/web/{port}", {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "client_ip": client_ip,
            "client_port": client_port,
            "bytes_in": bytes_in,
            "bytes_out": bytes_out,
            "duration_ms": duration_ms,
            "worker_id": worker_id,
            "connection_id": f"{client_ip}:{client_port}_{int(connection_start*1000)}"
        })

        # Stream 2: L2N tunnel metrics (async, outside lock)
        await push_to_backend(f"/api/v1/l2n/{port}", {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "backend_ip": target_ip,
            "backend_port": target_port,
            "duration_ms": duration_ms,
            "latency_ms": backend_latency,
            "worker_id": worker_id,
            "tunnel_status": "closed",
            "localtonet_gateway": "194.182.64.133:6921",
            "bytes_transferred": bytes_in + bytes_out
        })

        # Stream 8: Event log (append to circular buffer)
        with stats_lock:
            if port in CONNECTION_EVENTS:
                CONNECTION_EVENTS[port].append({
                    "timestamp": datetime.utcnow().isoformat() + "Z",
                    "event": "connection_closed",
                    "client": f"{client_ip}:{client_port}",
                    "duration_ms": duration_ms,
                    "latency_ms": backend_latency,
                    "bytes_transferred": bytes_in + bytes_out
                })

        # Update latency histogram for Stream 4
        with stats_lock:
            if port in LATENCY_HISTOGRAM:
                hist = LATENCY_HISTOGRAM[port]
                hist["count"] += 1
                hist["sum"] += backend_latency
                hist["min"] = min(hist["min"], backend_latency)
                hist["max"] = max(hist["max"], backend_latency)
                for b in LATENCY_BUCKETS:
                    if backend_latency <= b:
                        hist["buckets"][str(b)] += 1
            
            if port in PERFORMANCE_METRICS:
                perf = PERFORMANCE_METRICS[port]
                perf["latencies"].append(backend_latency)

    except Exception as e:
        logger.error(f"[{port}] HANDLER ERROR: {e}")
    finally:
        with stats_lock:
            if worker_id in WORKER_STATS:
                WORKER_STATS[worker_id]["active_tcp"] -= 1

        try:
            client_writer.close()
            await client_writer.wait_closed()
        except:
            pass
        if backend_writer:
            try:
                backend_writer.close()
                await backend_writer.wait_closed()
            except:
                pass

async def tcp_worker(port, target_ip, target_port, worker_id):
    """TCP worker process"""
    raise_limits()
    init_worker(worker_id)
    
    logger.info(f"âœ… [PORT {port}] TCP worker listening (worker_id: {worker_id})")
    server = await asyncio.start_server(
        lambda r, w: tcp_handler(r, w, port, target_ip, target_port, worker_id),
        LISTEN_IP, port, backlog=TCP_BACKLOG, reuse_address=True, reuse_port=True
    )
    async with server:
        await server.serve_forever()

# ============================================================================
# UDP RELAY
# ============================================================================

class UDPRelay(asyncio.DatagramProtocol):
    """UDP relay"""
    def __init__(self, port):
        self.target = PORT_MAP.get(port)
        self.transport = None

    def connection_made(self, transport):
        self.transport = transport

    def datagram_received(self, data, addr):
        if not self.target:
            return
        
        with stats_lock:
            GLOBAL_STATS["udp_packets"] += 1

        sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        try:
            sock.sendto(data, self.target)
            sock.settimeout(UDP_TIMEOUT)
            resp, _ = sock.recvfrom(65535)
            self.transport.sendto(resp, addr)
        except Exception:
            pass
        finally:
            sock.close()

async def udp_master(port):
    """UDP master for each port"""
    raise_limits()
    loop = asyncio.get_running_loop()
    
    await loop.create_datagram_endpoint(
        lambda: UDPRelay(port),
        local_addr=(LISTEN_IP, port),
    )
    logger.info(f"âœ… [PORT {port}] UDP relay listening")
    await asyncio.Event().wait()

# ============================================================================
# HEALTH CHECKS & MONITORING
# ============================================================================

async def check_target_tcp(port):
    """Check TCP target health"""
    ip, tport = PORT_MAP.get(port, (None, None))
    if not ip:
        return {"status": "unknown", "latency_ms": 0}

    start = time.time()
    try:
        r, w = await asyncio.wait_for(
            asyncio.open_connection(ip, tport),
            timeout=2
        )
        w.close()
        await w.wait_closed()

        latency = int((time.time() - start) * 1000)
        
        with stats_lock:
            if port in LATENCY_HISTOGRAM:
                hist = LATENCY_HISTOGRAM[port]
                hist["count"] += 1
                hist["sum"] += latency
                for b in LATENCY_BUCKETS:
                    if latency <= b:
                        hist["buckets"][str(b)] += 1

        return {"status": "up", "latency_ms": latency}
    except Exception as e:
        return {"status": "down", "error": str(e), "latency_ms": 0}

async def check_target_udp(port):
    """Check UDP target health"""
    ip, tport = PORT_MAP.get(port, (None, None))
    if not ip:
        return "unknown"

    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    sock.setblocking(False)
    try:
        sock.sendto(b"health", (ip, tport))
        with stats_lock:
            GLOBAL_STATS["udp_checks_ok"] += 1
        return "up"
    except Exception:
        with stats_lock:
            GLOBAL_STATS["udp_checks_fail"] += 1
        return "down"
    finally:
        sock.close()

async def monitor_loop():
    """Health check monitoring loop"""
    logger.info("âœ… Health monitor started (10-second intervals)")
    while True:
        try:
            for port in MONITORED_PORTS:
                tcp_health = await check_target_tcp(port)
                udp_health = await check_target_udp(port)
                
                with stats_lock:
                    MONITOR_STATE[port] = {
                        **tcp_health,
                        "udp_status": udp_health,
                        "checked_at": int(time.time())
                    }

                # Stream 7: Health status (async, outside lock)
                await push_to_backend(f"/api/v1/health/{port}", {
                    "timestamp": datetime.utcnow().isoformat() + "Z",
                    "port": port,
                    "tcp_status": tcp_health.get("status"),
                    "tcp_latency_ms": tcp_health.get("latency_ms"),
                    "udp_status": udp_health,
                    "uptime_sec": int(time.time())
                })

            await asyncio.sleep(HEALTH_CHECK_INTERVAL)
        except Exception as e:
            logger.error(f"Monitor error: {e}")
            await asyncio.sleep(HEALTH_CHECK_INTERVAL)

async def memory_cleanup_loop():
    """Aggressive memory cleanup - NO task backlog!"""
    logger.info("âœ… Memory cleanup started (30-second intervals)")
    cleanup_count = 0
    while True:
        try:
            await asyncio.sleep(MEMORY_CLEANUP_INTERVAL)
            cleanup_count += 1
            
            # Collect data INSIDE lock
            with stats_lock:
                cleanup_tasks = []
                
                # Stream 5: Throughput stats
                for port in MONITORED_PORTS:
                    if port in THROUGHPUT_WINDOW:
                        window = THROUGHPUT_WINDOW[port]
                        elapsed = time.time() - window.get("window_start", time.time())
                        if elapsed > 0:
                            bytes_per_sec = (window["bytes_in"] + window["bytes_out"]) / elapsed
                            conn_per_sec = window["connections"] / elapsed
                            
                            cleanup_tasks.append(push_to_backend(f"/api/v1/throughput/{port}", {
                                "timestamp": datetime.utcnow().isoformat() + "Z",
                                "port": port,
                                "bytes_per_sec": int(bytes_per_sec),
                                "connections_per_sec": round(conn_per_sec, 2),
                                "total_bytes_in": window["bytes_in"],
                                "total_bytes_out": window["bytes_out"],
                                "total_connections": window["connections"]
                            }))
                            
                            # Reset window
                            THROUGHPUT_WINDOW[port] = {
                                "bytes_in": 0,
                                "bytes_out": 0,
                                "connections": 0,
                                "window_start": time.time()
                            }
                    
                    # Stream 4: Performance metrics (p50/p95/p99)
                    if port in PERFORMANCE_METRICS:
                        perf = PERFORMANCE_METRICS[port]
                        latencies = list(perf["latencies"])
                        if latencies:
                            latencies.sort()
                            n = len(latencies)
                            p50 = latencies[int(n * 0.50)]
                            p95 = latencies[int(n * 0.95)]
                            p99 = latencies[int(n * 0.99)]
                            
                            cleanup_tasks.append(push_to_backend(f"/api/v1/performance/{port}", {
                                "timestamp": datetime.utcnow().isoformat() + "Z",
                                "port": port,
                                "p50": p50,
                                "p95": p95,
                                "p99": p99,
                                "min": perf["min"] if perf["min"] != float('inf') else 0,
                                "max": perf["max"],
                                "sample_count": n
                            }))
                    
                    # Stream 8: Event log
                    if port in CONNECTION_EVENTS and len(CONNECTION_EVENTS[port]) > 0:
                        events = list(CONNECTION_EVENTS[port])
                        if events:
                            cleanup_tasks.append(push_to_backend(f"/api/v1/events/{port}", {
                                "timestamp": datetime.utcnow().isoformat() + "Z",
                                "port": port,
                                "events": events,
                                "count": len(events)
                            }))
                
                # Stream 6: Worker health
                worker_snapshot = {}
                for worker_id, stats in WORKER_STATS.items():
                    worker_snapshot[worker_id] = dict(stats)
                
                if worker_snapshot:
                    cleanup_tasks.append(push_to_backend(f"/api/v1/workers/status", {
                        "timestamp": datetime.utcnow().isoformat() + "Z",
                        "workers": worker_snapshot,
                        "worker_count": len(worker_snapshot)
                    }))
            
            # AWAIT TASKS OUTSIDE LOCK (CRITICAL FIX!)
            if cleanup_tasks:
                await asyncio.gather(*cleanup_tasks, return_exceptions=True)
            
            logger.debug(f"Cleanup #{cleanup_count}: Flushed all 8 streams, memory stable (~7-10MB)")
                
        except Exception as e:
            logger.error(f"Cleanup error: {e}")

# ============================================================================
# PROMETHEUS METRICS
# ============================================================================

def prometheus_metrics():
    """Generate Prometheus metrics output"""
    lines = []

    with stats_lock:
        for worker_id, stats in WORKER_STATS.items():
            for k, v in stats.items():
                if isinstance(v, (int, float)):
                    lines.append(f'redirector_worker_{k}{{worker_id="{worker_id}"}} {v}')

        for k, v in GLOBAL_STATS.items():
            if isinstance(v, (int, float)):
                lines.append(f"redirector_{k} {v}")

        for port, hist in LATENCY_HISTOGRAM.items():
            cum = 0
            for b in LATENCY_BUCKETS:
                cum += hist["buckets"][str(b)]
                lines.append(f'redirector_tcp_latency_ms_bucket{{port="{port}",le="{b}"}} {cum}')
            lines.append(f'redirector_tcp_latency_ms_count{{port="{port}"}} {hist["count"]}')
            lines.append(f'redirector_tcp_latency_ms_sum{{port="{port}"}} {hist["sum"]}')

    return "\n".join(lines) + "\n"

# ============================================================================
# HTTP API - MONITORING & METRICS
# ============================================================================

@web.middleware
async def auth_middleware(request, handler):
    """Authentication middleware"""
    if request.headers.get("Authorization") != f"Bearer {API_AUTH_TOKEN}":
        return web.json_response({"error": "unauthorized"}, status=401)
    return await handler(request)

def system_stats():
    """Get system stats"""
    try:
        return {
            "cpu_percent": psutil.cpu_percent(interval=0.1),
            "load_avg": os.getloadavg(),
            "ram": dict(psutil.virtual_memory()._asdict()),
            "uptime_sec": int(time.time() - psutil.boot_time()),
            "net": dict(psutil.net_io_counters()._asdict())
        }
    except Exception as e:
        return {"error": str(e)}

async def status_handler(request):
    """Status endpoint"""
    with stats_lock:
        return web.json_response({
            "ports": dict(MONITOR_STATE),
            "workers": {k: {mk: mv for mk, mv in v.items() if mk not in ["connection_history"]} 
                       for k, v in WORKER_STATS.items()},
            "global": dict(GLOBAL_STATS),
            "system": system_stats(),
            "timestamp": datetime.utcnow().isoformat()
        })

async def metrics_handler(request):
    """Prometheus metrics endpoint"""
    return web.Response(text=prometheus_metrics(), content_type="text/plain")

async def health_handler(request):
    """Health check endpoint"""
    return web.json_response({
        "status": "ok",
        "version": "4.1.6-hotfix",
        "timestamp": datetime.utcnow().isoformat()
    })

async def start_http_server():
    """Start HTTP monitoring server"""
    raise_limits()
    app = web.Application(middlewares=[auth_middleware])
    app.router.add_get("/health", health_handler)
    app.router.add_get("/status", status_handler)
    app.router.add_get("/metrics", metrics_handler)
    
    runner = web.AppRunner(app)
    await runner.setup()
    site = web.TCPSite(runner, "0.0.0.0", 9090, reuse_address=True)
    await site.start()
    logger.info("âœ… HTTP monitoring server listening on :9090")
    
    await asyncio.Event().wait()

# ============================================================================
# PROCESS ENTRY POINTS
# ============================================================================

def run_tcp_worker(port, target_ip, target_port, worker_id):
    """TCP worker entry point"""
    raise_limits()
    asyncio.run(tcp_worker(port, target_ip, target_port, worker_id))

def run_udp_worker(port):
    """UDP worker entry point"""
    raise_limits()
    asyncio.run(udp_master(port))

def run_monitor():
    """Monitor entry point"""
    raise_limits()
    asyncio.run(monitor_loop())

def run_http_server():
    """HTTP server entry point"""
    raise_limits()
    asyncio.run(start_http_server())

def run_cleanup():
    """Cleanup entry point"""
    raise_limits()
    asyncio.run(memory_cleanup_loop())

# ============================================================================
# MAIN
# ============================================================================

def main():
    """Main entry point"""
    if os.geteuid() != 0:
        raise SystemExit("Run as root")

    raise_limits()
    init_latency_histograms()

    logger.info("=" * 100)
    logger.info("ðŸš€ L4 REDIRECTOR v4.1.6 EMERGENCY HOTFIX - TASK BACKLOG FIXED")
    logger.info("=" * 100)
    logger.info(f"ðŸ“¡ Backend API: {BACKEND_API_URL}")
    logger.info(f"âœ… TCP + UDP forwarding active")
    logger.info(f"âœ… 8 comprehensive data streams to Windows backend")
    logger.info(f"âœ… Memory cleanup every {MEMORY_CLEANUP_INTERVAL} seconds")
    logger.info(f"ðŸ”¥ CRITICAL: Task backlog memory leak FIXED")
    logger.info("=" * 100)
    logger.info("Data Streams:")
    logger.info("  1. /api/v1/web/{port} - Client traffic metrics")
    logger.info("  2. /api/v1/l2n/{port} - Backend L2N tunnel metrics")
    logger.info("  3. /api/v1/errors/l2n/{port} - Connection errors")
    logger.info("  4. /api/v1/performance/{port} - Latency percentiles (p50/p95/p99)")
    logger.info("  5. /api/v1/throughput/{port} - Real-time throughput")
    logger.info("  6. /api/v1/workers/status - Worker health & resource usage")
    logger.info("  7. /api/v1/health/{port} - Port availability")
    logger.info("  8. /api/v1/events/{port} - Connection lifecycle events")
    logger.info("=" * 100)

    processes = []
    cpu_count = os.cpu_count() or 2

    try:
        # Monitor process
        p = multiprocessing.Process(target=run_monitor)
        p.daemon = False
        p.start()
        processes.append(p)
        time.sleep(0.5)

        # Memory cleanup process
        p = multiprocessing.Process(target=run_cleanup)
        p.daemon = False
        p.start()
        processes.append(p)
        time.sleep(0.5)

        # HTTP server
        p = multiprocessing.Process(target=run_http_server)
        p.daemon = False
        p.start()
        processes.append(p)
        time.sleep(0.5)

        # TCP workers
        for port, (target_ip, target_port) in PORT_MAP.items():
            for i in range(cpu_count * 4):
                worker_id = f"tcp_{port}_{i}"
                p = multiprocessing.Process(
                    target=run_tcp_worker,
                    args=(port, target_ip, target_port, worker_id)
                )
                p.daemon = False
                p.start()
                processes.append(p)
                time.sleep(0.05)

        # UDP workers
        for port in PORT_MAP.keys():
            p = multiprocessing.Process(target=run_udp_worker, args=(port,))
            p.daemon = False
            p.start()
            processes.append(p)
            time.sleep(0.1)

        logger.info(f"âœ… All {len(processes)} processes started")
        logger.info(f"âœ… Ready for {cpu_count * 4 * 3} concurrent TCP connections per port")
        logger.info(f"ðŸ“Š Metrics: :9090/metrics | Status: :9090/status")
        logger.info("")

        while True:
            time.sleep(5)
            alive = [p for p in processes if p.is_alive()]
            if len(alive) < len(processes):
                logger.warning(f"âš ï¸  Process crashed! ({len(alive)}/{len(processes)} alive)")
                processes = alive

    except KeyboardInterrupt:
        logger.info("â¹ï¸  Shutting down...")
    finally:
        for p in processes:
            if p.is_alive():
                p.terminate()
        for p in processes:
            p.join(timeout=5)
            if p.is_alive():
                p.kill()
        logger.info("âœ… All processes stopped")

if __name__ == '__main__':
    main()
