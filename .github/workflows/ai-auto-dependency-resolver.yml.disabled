name: ðŸ¤– AI Auto-Fix & Dependency Resolver

on:
  pull_request:
    types: [opened, synchronize, reopened]
  workflow_dispatch:
  workflow_call:

env:
  # 16 AI provider API keys
  CEREBRAS_API_KEY: ${{ secrets.CEREBRAS_API_KEY }}
  CODESTRAL_API_KEY: ${{ secrets.CODESTRAL_API_KEY }}
  DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
  GEMINIAI_API_KEY: ${{ secrets.GEMINIAI_API_KEY }}
  GLM_API_KEY: ${{ secrets.GLM_API_KEY }}
  GPTOSS_API_KEY: ${{ secrets.GPTOSS_API_KEY }}
  GROK_API_KEY: ${{ secrets.GROK_API_KEY }}
  GROQAI_API_KEY: ${{ secrets.GROQAI_API_KEY }}
  KIMI_API_KEY: ${{ secrets.KIMI_API_KEY }}
  NVIDIA_API_KEY: ${{ secrets.NVIDIA_API_KEY }}
  QWEN_API_KEY: ${{ secrets.QWEN_API_KEY }}
  GEMINI2_API_KEY: ${{ secrets.GEMINI2_API_KEY }}
  GROQ2_API_KEY: ${{ secrets.GROQ2_API_KEY }}
  COHERE_API_KEY: ${{ secrets.COHERE_API_KEY }}
  CHUTES_API_KEY: ${{ secrets.CHUTES_API_KEY }}
  CLAUDE_API_KEY: ${{ secrets.CLAUDE_API_KEY }}
  GPT4_API_KEY: ${{ secrets.GPT4_API_KEY }}

jobs:
  dependency_analysis:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    outputs:
      has_issues: ${{ steps.analyze.outputs.has_issues }}
      issue_count: ${{ steps.analyze.outputs.issue_count }}
    
    steps:
      - name: ðŸ“¥ Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: ðŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: 'pip'

      - name: ðŸ“¦ Install Base Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install aiohttp openai cohere python-dotenv
          pip install multidict yarl attrs aiosignal frozenlist
          pip install -r requirements.txt

      - name: ðŸ§ª Run AI Dependency Resolver
        id: analyze
        run: |
          echo "ðŸš€ Launching AI Dependency Resolver..."
          
          # Create artifacts directory
          mkdir -p artifacts
          
          # Run the AI dependency resolver
          python .github/scripts/ai_dependency_resolver.py || {
            echo "âš ï¸ AI Dependency Resolver completed with warnings"
            # Create minimal results even if script fails
            echo '{"metadata":{"status":"completed_with_warnings"},"issues_detected":{"missing_modules":[],"error_count":0},"ai_analysis":{"analysis":"Analysis completed with warnings"},"fixes_applied":{"total_applied":0,"total_failed":0}}' > artifacts/dependency_resolution.json
          }
          
          # Check if issues were found
          if [ -f "artifacts/dependency_resolution.json" ]; then
            ISSUE_COUNT=$(python -c "
          import json
          try:
              with open('artifacts/dependency_resolution.json', 'r') as f:
                  data = json.load(f)
              missing = data.get('issues_detected', {}).get('missing_modules', [])
              print(len(missing))
          except:
              print(0)
          ")
            echo "issue_count=$ISSUE_COUNT" >> $GITHUB_OUTPUT
            echo "has_issues=$([ $ISSUE_COUNT -gt 0 ] && echo 'true' || echo 'false')" >> $GITHUB_OUTPUT
          else
            echo "issue_count=0" >> $GITHUB_OUTPUT
            echo "has_issues=false" >> $GITHUB_OUTPUT
          fi

      - name: ðŸ’¾ Upload Analysis Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ai-dependency-analysis-${{ github.run_number }}
          path: |
            artifacts/dependency_resolution.json
            artifacts/
          retention-days: 30

  auto_fix_application:
    runs-on: ubuntu-latest
    needs: dependency_analysis
    if: needs.dependency_analysis.outputs.has_issues == 'true'
    timeout-minutes: 10
    
    steps:
      - name: ðŸ“¥ Checkout Repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      - name: ðŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: ðŸ“¥ Download Analysis Results
        uses: actions/download-artifact@v4
        with:
          name: ai-dependency-analysis-${{ github.run_number }}
          path: artifacts/

      - name: ðŸ“¦ Install Dependencies First
        run: |
          echo "ðŸ“¦ Installing required dependencies..."
          python -m pip install --upgrade pip
          pip install aiohttp multidict yarl attrs aiosignal frozenlist
          pip install openai cohere python-dotenv
          pip install -r requirements.txt || echo "Some requirements failed, continuing..."

      - name: ðŸ”§ Apply AI-Suggested Fixes
        run: |
          echo "ðŸ”§ Applying AI-suggested dependency fixes..."
          
          if [ -f "artifacts/dependency_resolution.json" ]; then
            # Extract and run pip commands
            python -c "
import json
import subprocess
import sys

try:
    with open('artifacts/dependency_resolution.json', 'r') as f:
        data = json.load(f)
    
    commands = data.get('ai_analysis', {}).get('pip_commands', [])
    print(f'Found {len(commands)} suggested commands')
    
    for cmd in commands[:5]:  # Limit to 5 commands
        print(f'Running: {cmd}')
        try:
            result = subprocess.run(cmd.split(), capture_output=True, text=True, timeout=60)
            if result.returncode == 0:
                print(f'âœ… Success: {cmd}')
            else:
                print(f'âŒ Failed: {cmd} - {result.stderr}')
        except Exception as e:
            print(f'âŒ Exception: {cmd} - {e}')
except Exception as e:
    print(f'Error processing fixes: {e}')
"

      - name: ðŸ“ Update Requirements.txt (if suggested)
        run: |
          echo "ðŸ“ Checking for requirements.txt updates..."
          
          if [ -f "artifacts/dependency_resolution.json" ]; then
            python -c "
          import json
          import os
          
          try:
              with open('artifacts/dependency_resolution.json', 'r') as f:
                  data = json.load(f)
              
              req_content = data.get('ai_analysis', {}).get('requirements_txt', '')
              if req_content and req_content.strip():
                  print('Updating requirements.txt with AI suggestions...')
                  with open('requirements.txt', 'w') as f:
                      f.write(req_content)
                  print('âœ… requirements.txt updated')
              else:
                  print('No requirements.txt updates suggested')
          except Exception as e:
              print(f'Error updating requirements.txt: {e}')
          "

      - name: ðŸ§ª Test Applied Fixes
        run: |
          echo "ðŸ§ª Testing applied fixes..."
          python -c "
          import sys
          import importlib
          
          # Test common imports that were failing
          test_modules = ['aiohttp', 'openai', 'cohere', 'multidict', 'yarl', 'attrs']
          
          for module in test_modules:
              try:
                  importlib.import_module(module)
                  print(f'âœ… {module} - OK')
              except ImportError as e:
                  print(f'âŒ {module} - FAILED: {e}')
          "

  pr_comment:
    runs-on: ubuntu-latest
    needs: [dependency_analysis, auto_fix_application]
    if: always() && github.event_name == 'pull_request'
    timeout-minutes: 5
    
    steps:
      - name: ðŸ“¥ Checkout Repository
        uses: actions/checkout@v4

      - name: ðŸ“¥ Download Analysis Results
        uses: actions/download-artifact@v4
        with:
          name: ai-dependency-analysis-${{ github.run_number }}
          path: artifacts/
        continue-on-error: true

      - name: ðŸ“ Post AI Analysis to PR
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            // Safe access to job outputs with fallbacks
            const dependencyAnalysisResult = '${{ needs.dependency_analysis.result }}';
            const issueCount = '${{ needs.dependency_analysis.outputs.issue_count }}' || '0';
            const autoFixResult = '${{ needs.auto_fix_application.result }}';
            
            let comment = `## ðŸ¤– AI Dependency & Code-Fix Analysis
            
            **Status:** ${dependencyAnalysisResult === 'success' ? 'âœ… Completed' : 'âŒ Failed'}
            **Issues Detected:** ${issueCount}
            **Auto-Fix Applied:** ${autoFixResult === 'success' ? 'âœ… Yes' : 'âŒ No'}
            
            ---
            `;
            
            // Try to read analysis results
            let analysisData = null;
            if (fs.existsSync('artifacts/dependency_resolution.json')) {
              try {
                analysisData = JSON.parse(fs.readFileSync('artifacts/dependency_resolution.json', 'utf8'));
              } catch (error) {
                console.log('Error parsing analysis results:', error.message);
              }
            }
            
            if (analysisData) {
              // Add metadata
              comment += `**ðŸ¤– AI Provider:** ${analysisData.metadata?.provider_used || 'Unknown'}
              **â±ï¸ Response Time:** ${analysisData.metadata?.response_time || 0}s
              **ðŸ”§ Fixes Applied:** ${analysisData.fixes_applied?.total_applied || 0}
              **âŒ Fixes Failed:** ${analysisData.fixes_applied?.total_failed || 0}
              
              ---
              `;
              
              // Add analysis
              if (analysisData.ai_analysis) {
                comment += `### ðŸ” Analysis
                **Root Cause:** ${analysisData.ai_analysis.root_cause || 'Unknown'}
                **Priority:** ${analysisData.ai_analysis.priority || 'Unknown'}
                **Confidence:** ${(analysisData.ai_analysis.confidence || 0) * 100}%
                
                **Analysis:** ${analysisData.ai_analysis.analysis || 'No analysis available'}
                
                ---
                `;
              }
              
              // Add recommendations
              if (analysisData.recommendations?.immediate_actions?.length > 0) {
                comment += `### ðŸ“¦ Immediate Actions
                \`\`\`bash
                ${analysisData.recommendations.immediate_actions.slice(0, 5).join('\n')}
                \`\`\`
                
                ---
                `;
              }
              
              // Add long-term improvements
              if (analysisData.recommendations?.long_term_improvements?.length > 0) {
                comment += `### ðŸš€ Long-term Improvements
                ${analysisData.recommendations.long_term_improvements.map(imp => `- ${imp}`).join('\n')}
                
                ---
                `;
              }
              
              // Add workflow changes
              if (analysisData.recommendations?.workflow_changes?.length > 0) {
                comment += `### âš™ï¸ Workflow Changes
                ${analysisData.recommendations.workflow_changes.map(change => `- ${change}`).join('\n')}
                
                ---
                `;
              }
            } else {
              comment += `**â„¹ï¸ Analysis Status:** No detailed analysis results available
              
              This could mean:
              - No dependency issues were detected
              - The AI analysis is still processing
              - There was an issue with the analysis script
              
              ---
              `;
            }
            
            comment += `
            ---
            
            *ðŸ¤– Generated by AI Dependency Resolver at ${new Date().toISOString()}*
            *Using 16-provider fallback system for maximum reliability*
            `;
            
            // Post comment to PR
            try {
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
              console.log('âœ… PR comment posted successfully');
            } catch (error) {
              console.log('âŒ Failed to post PR comment:', error.message);
              throw error;
            }

  summary:
    runs-on: ubuntu-latest
    needs: [dependency_analysis, auto_fix_application, pr_comment]
    if: always()
    timeout-minutes: 2
    
    steps:
      - name: ðŸ“Š Generate Workflow Summary
        run: |
          echo "## ðŸ¤– AI Dependency Resolver Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Job | Status | Details |" >> $GITHUB_STEP_SUMMARY
          echo "|-----|--------|---------|" >> $GITHUB_STEP_SUMMARY
          echo "| ðŸ” Dependency Analysis | ${{ needs.dependency_analysis.result }} | Issues: ${{ needs.dependency_analysis.outputs.issue_count || 0 }} |" >> $GITHUB_STEP_SUMMARY
          echo "| ðŸ”§ Auto-Fix Application | ${{ needs.auto_fix_application.result }} | ${{ needs.auto_fix_application.result == 'success' && 'Applied' || 'Skipped/Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| ðŸ“ PR Comment | ${{ needs.pr_comment.result }} | ${{ needs.pr_comment.result == 'success' && 'Posted' || 'Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**ðŸŽ¯ Result:** ${{ needs.dependency_analysis.result == 'success' && 'Dependencies analyzed and fixes applied' || 'Analysis failed - check logs' }}" >> $GITHUB_STEP_SUMMARY