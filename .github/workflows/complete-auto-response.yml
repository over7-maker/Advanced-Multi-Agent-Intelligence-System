# Version: v1.0.0
# Generated by AMAS Release System
name: Complete Auto Response System

# Multiple triggers to ensure it works
on:
  issues:
    types: [opened, edited, labeled]
  workflow_dispatch:
    inputs:
      issue_number:
        description: 'Issue number to analyze'
        required: false
        type: string
  schedule:
    - cron: '0 */2 * * *'  # Every 2 hours to catch any missed issues

jobs:
  # Pre-check to ensure we have the right conditions
  pre-check:
    runs-on: ubuntu-latest
    outputs:
      should-run: ${{ steps.check.outputs.should-run }}
      issue-number: ${{ steps.check.outputs.issue-number }}
    
    steps:
    - name: Check if we should run
      id: check
      run: |
        # Check if this is an issue (not PR)
        if [ "${{ github.event_name }}" = "issues" ]; then
          echo "should-run=true" >> $GITHUB_OUTPUT
          echo "issue-number=${{ github.event.issue.number }}" >> $GITHUB_OUTPUT
        elif [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          if [ -n "${{ github.event.inputs.issue_number }}" ]; then
            echo "should-run=true" >> $GITHUB_OUTPUT
            echo "issue-number=${{ github.event.inputs.issue_number }}" >> $GITHUB_OUTPUT
          else
            echo "should-run=false" >> $GITHUB_OUTPUT
          fi
        else
          echo "should-run=false" >> $GITHUB_OUTPUT
        fi

  # Simple Auto Response
  simple-auto-response:
    runs-on: ubuntu-latest
    needs: pre-check
    if: needs.pre-check.outputs.should-run == 'true'
    
    permissions:
      issues: write
      contents: read
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        pip install requests openai python-dotenv
    
    - name: Simple AI Response
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
        DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
        ISSUE_NUMBER: ${{ needs.pre-check.outputs.issue-number }}
        ISSUE_TITLE: ${{ github.event.issue.title }}
        ISSUE_BODY: ${{ github.event.issue.body }}
        ISSUE_AUTHOR: ${{ github.event.issue.user.login }}
        REPO_NAME: ${{ github.repository }}
      run: |
        python .github/scripts/simple_ai_responder.py
    
    - name: Add AI Analysis Labels
      uses: actions/github-script@v7
      with:
        script: |
          const issueNumber = ${{ needs.pre-check.outputs.issue-number }};
          await github.rest.issues.addLabels({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: issueNumber,
            labels: ['ai-analyzed', 'auto-response']
          });

  # Enhanced Analysis (if API keys are available)
  enhanced-analysis:
    runs-on: ubuntu-latest
    needs: [pre-check, simple-auto-response]
    if: needs.pre-check.outputs.should-run == 'true' && always()
    
    permissions:
      issues: write
      contents: read
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        pip install requests openai python-dotenv PyGithub
    
    - name: Enhanced AI Analysis
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
        DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
        ISSUE_NUMBER: ${{ needs.pre-check.outputs.issue-number }}
        ISSUE_TITLE: ${{ github.event.issue.title }}
        ISSUE_BODY: ${{ github.event.issue.body }}
        ISSUE_AUTHOR: ${{ github.event.issue.user.login }}
        REPO_NAME: ${{ github.repository }}
      run: |
        python .github/scripts/ai_issue_responder.py || echo "Enhanced analysis failed, but simple response was successful"
    
    - name: Multi-Agent Analysis
      env:
        DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
        GLM_API_KEY: ${{ secrets.GLM_API_KEY }}
        GROK_API_KEY: ${{ secrets.GROK_API_KEY }}
        ISSUE_NUMBER: ${{ needs.pre-check.outputs.issue-number }}
        REPO_NAME: ${{ github.repository }}
      run: |
        mkdir -p artifacts
        python .github/scripts/multi_agent_orchestrator.py || echo "Multi-agent analysis failed, but simple response was successful"
    
    - name: Issue Resolution Integration
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
        DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
        ISSUE_NUMBER: ${{ needs.pre-check.outputs.issue-number }}
        REPO_NAME: ${{ github.repository }}
      run: |
        python .github/scripts/issue_resolution_integrator.py || echo "Resolution integration failed, but simple response was successful"
    
    - name: Add Enhanced Labels
      uses: actions/github-script@v7
      with:
        script: |
          const issueNumber = ${{ needs.pre-check.outputs.issue-number }};
          await github.rest.issues.addLabels({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: issueNumber,
            labels: ['enhanced-analysis', 'multi-agent-reviewed']
          });

  # Status Report
  status-report:
    runs-on: ubuntu-latest
    needs: [pre-check, simple-auto-response, enhanced-analysis]
    if: always()
    
    permissions:
      issues: write
      contents: read
    
    steps:
    - name: Generate Status Report
      run: |
        echo "# ðŸ¤– Auto Response Status Report" > status-report.md
        echo "Generated: $(date)" >> status-report.md
        echo "" >> status-report.md
        echo "## Workflow Status" >> status-report.md
        echo "- Pre-check: ${{ needs.pre-check.result }}" >> status-report.md
        echo "- Simple Auto Response: ${{ needs.simple-auto-response.result }}" >> status-report.md
        echo "- Enhanced Analysis: ${{ needs.enhanced-analysis.result }}" >> status-report.md
        echo "" >> status-report.md
        echo "## Issue Processing" >> status-report.md
        echo "- Issue Number: ${{ needs.pre-check.outputs.issue-number }}" >> status-report.md
        echo "- Issue Title: ${{ github.event.issue.title }}" >> status-report.md
        echo "- Issue Author: ${{ github.event.issue.user.login }}" >> status-report.md
        echo "" >> status-report.md
        echo "## Next Steps" >> status-report.md
        echo "1. Check the issue for AI-generated responses" >> status-report.md
        echo "2. Verify labels were added correctly" >> status-report.md
        echo "3. Review any generated analysis reports" >> status-report.md
    
    - name: Upload Status Report
      uses: actions/upload-artifact@v4
      with:
        name: auto-response-status
        path: status-report.md
    
    - name: Comment Status on Issue
      if: needs.pre-check.outputs.should-run == 'true'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const report = fs.readFileSync('status-report.md', 'utf8');
          
          github.rest.issues.createComment({
            issue_number: ${{ needs.pre-check.outputs.issue-number }},
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: `## ðŸ¤– Auto Response Status\n\n${report}`
          });