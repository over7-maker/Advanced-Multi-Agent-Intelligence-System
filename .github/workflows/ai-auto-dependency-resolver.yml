name: 🤖 AI Auto-Fix & Dependency Resolver

on:
  pull_request:
    types: [opened, synchronize, reopened]
  workflow_dispatch:
  workflow_call:

env:
  # 16 AI provider API keys
  CEREBRAS_API_KEY: ${{ secrets.CEREBRAS_API_KEY }}
  CODESTRAL_API_KEY: ${{ secrets.CODESTRAL_API_KEY }}
  DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
  GEMINIAI_API_KEY: ${{ secrets.GEMINIAI_API_KEY }}
  GLM_API_KEY: ${{ secrets.GLM_API_KEY }}
  GPTOSS_API_KEY: ${{ secrets.GPTOSS_API_KEY }}
  GROK_API_KEY: ${{ secrets.GROK_API_KEY }}
  GROQAI_API_KEY: ${{ secrets.GROQAI_API_KEY }}
  KIMI_API_KEY: ${{ secrets.KIMI_API_KEY }}
  NVIDIA_API_KEY: ${{ secrets.NVIDIA_API_KEY }}
  QWEN_API_KEY: ${{ secrets.QWEN_API_KEY }}
  GEMINI2_API_KEY: ${{ secrets.GEMINI2_API_KEY }}
  GROQ2_API_KEY: ${{ secrets.GROQ2_API_KEY }}
  COHERE_API_KEY: ${{ secrets.COHERE_API_KEY }}
  CHUTES_API_KEY: ${{ secrets.CHUTES_API_KEY }}
  CLAUDE_API_KEY: ${{ secrets.CLAUDE_API_KEY }}
  GPT4_API_KEY: ${{ secrets.GPT4_API_KEY }}

jobs:
  dependency_analysis:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    outputs:
      has_issues: ${{ steps.analyze.outputs.has_issues }}
      issue_count: ${{ steps.analyze.outputs.issue_count }}
    
    steps:
      - name: 📥 Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: 🐍 Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: 'pip'

      - name: 📦 Install Base Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install aiohttp openai cohere python-dotenv
          pip install multidict yarl attrs aiosignal frozenlist || true

      - name: 🧪 Run AI Dependency Resolver
        id: analyze
        run: |
          echo "🚀 Launching AI Dependency Resolver..."
          
          # Create artifacts directory
          mkdir -p artifacts
          
          # Run the AI dependency resolver
          python .github/scripts/ai_dependency_resolver.py || {
            echo "⚠️ AI Dependency Resolver completed with warnings"
            # Create minimal results even if script fails
            echo '{"metadata":{"status":"completed_with_warnings"},"issues_detected":{"missing_modules":[],"error_count":0},"ai_analysis":{"analysis":"Analysis completed with warnings"},"fixes_applied":{"total_applied":0,"total_failed":0}}' > artifacts/dependency_resolution.json
          }
          
          # Check if issues were found
          if [ -f "artifacts/dependency_resolution.json" ]; then
            ISSUE_COUNT=$(python -c "
          import json
          try:
              with open('artifacts/dependency_resolution.json', 'r') as f:
                  data = json.load(f)
              missing = data.get('issues_detected', {}).get('missing_modules', [])
              print(len(missing))
          except:
              print(0)
          ")
            echo "issue_count=$ISSUE_COUNT" >> $GITHUB_OUTPUT
            echo "has_issues=$([ $ISSUE_COUNT -gt 0 ] && echo 'true' || echo 'false')" >> $GITHUB_OUTPUT
          else
            echo "issue_count=0" >> $GITHUB_OUTPUT
            echo "has_issues=false" >> $GITHUB_OUTPUT
          fi

      - name: 💾 Upload Analysis Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ai-dependency-analysis-${{ github.run_number }}
          path: |
            artifacts/dependency_resolution.json
            artifacts/
          retention-days: 30

  auto_fix_application:
    runs-on: ubuntu-latest
    needs: dependency_analysis
    if: needs.dependency_analysis.outputs.has_issues == 'true'
    timeout-minutes: 10
    
    steps:
      - name: 📥 Checkout Repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      - name: 🐍 Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: 📥 Download Analysis Results
        uses: actions/download-artifact@v4
        with:
          name: ai-dependency-analysis-${{ github.run_number }}
          path: artifacts/

      - name: 🔧 Apply AI-Suggested Fixes
        run: |
          echo "🔧 Applying AI-suggested dependency fixes..."
          
          if [ -f "artifacts/dependency_resolution.json" ]; then
            # Extract and run pip commands
            python -c "
          import json
          import subprocess
          import sys
          
          try:
              with open('artifacts/dependency_resolution.json', 'r') as f:
                  data = json.load(f)
              
              commands = data.get('ai_analysis', {}).get('pip_commands', [])
              print(f'Found {len(commands)} suggested commands')
              
              for cmd in commands[:5]:  # Limit to 5 commands
                  print(f'Running: {cmd}')
                  try:
                      result = subprocess.run(cmd.split(), capture_output=True, text=True, timeout=60)
                      if result.returncode == 0:
                          print(f'✅ Success: {cmd}')
                      else:
                          print(f'❌ Failed: {cmd} - {result.stderr}')
                  except Exception as e:
                      print(f'❌ Exception: {cmd} - {e}')
          except Exception as e:
              print(f'Error processing fixes: {e}')
          "

      - name: 📝 Update Requirements.txt (if suggested)
        run: |
          echo "📝 Checking for requirements.txt updates..."
          
          if [ -f "artifacts/dependency_resolution.json" ]; then
            python -c "
          import json
          import os
          
          try:
              with open('artifacts/dependency_resolution.json', 'r') as f:
                  data = json.load(f)
              
              req_content = data.get('ai_analysis', {}).get('requirements_txt', '')
              if req_content and req_content.strip():
                  print('Updating requirements.txt with AI suggestions...')
                  with open('requirements.txt', 'w') as f:
                      f.write(req_content)
                  print('✅ requirements.txt updated')
              else:
                  print('No requirements.txt updates suggested')
          except Exception as e:
              print(f'Error updating requirements.txt: {e}')
          "

      - name: 🧪 Test Applied Fixes
        run: |
          echo "🧪 Testing applied fixes..."
          python -c "
          import sys
          import importlib
          
          # Test common imports that were failing
          test_modules = ['aiohttp', 'openai', 'cohere', 'multidict', 'yarl', 'attrs']
          
          for module in test_modules:
              try:
                  importlib.import_module(module)
                  print(f'✅ {module} - OK')
              except ImportError as e:
                  print(f'❌ {module} - FAILED: {e}')
          "

  pr_comment:
    runs-on: ubuntu-latest
    needs: [dependency_analysis, auto_fix_application]
    if: always() && github.event_name == 'pull_request'
    timeout-minutes: 5
    
    steps:
      - name: 📥 Checkout Repository
        uses: actions/checkout@v4

      - name: 📥 Download Analysis Results
        uses: actions/download-artifact@v4
        with:
          name: ai-dependency-analysis-${{ github.run_number }}
          path: artifacts/
        continue-on-error: true

      - name: 📝 Post AI Analysis to PR
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            // Safe access to job outputs with fallbacks
            const dependencyAnalysisResult = '${{ needs.dependency_analysis.result }}';
            const issueCount = '${{ needs.dependency_analysis.outputs.issue_count }}' || '0';
            const autoFixResult = '${{ needs.auto_fix_application.result }}';
            
            let comment = `## 🤖 AI Dependency & Code-Fix Analysis
            
            **Status:** ${dependencyAnalysisResult === 'success' ? '✅ Completed' : '❌ Failed'}
            **Issues Detected:** ${issueCount}
            **Auto-Fix Applied:** ${autoFixResult === 'success' ? '✅ Yes' : '❌ No'}
            
            ---
            `;
            
            // Try to read analysis results
            let analysisData = null;
            if (fs.existsSync('artifacts/dependency_resolution.json')) {
              try {
                analysisData = JSON.parse(fs.readFileSync('artifacts/dependency_resolution.json', 'utf8'));
              } catch (error) {
                console.log('Error parsing analysis results:', error.message);
              }
            }
            
            if (analysisData) {
              // Add metadata
              comment += `**🤖 AI Provider:** ${analysisData.metadata?.provider_used || 'Unknown'}
              **⏱️ Response Time:** ${analysisData.metadata?.response_time || 0}s
              **🔧 Fixes Applied:** ${analysisData.fixes_applied?.total_applied || 0}
              **❌ Fixes Failed:** ${analysisData.fixes_applied?.total_failed || 0}
              
              ---
              `;
              
              // Add analysis
              if (analysisData.ai_analysis) {
                comment += `### 🔍 Analysis
                **Root Cause:** ${analysisData.ai_analysis.root_cause || 'Unknown'}
                **Priority:** ${analysisData.ai_analysis.priority || 'Unknown'}
                **Confidence:** ${(analysisData.ai_analysis.confidence || 0) * 100}%
                
                **Analysis:** ${analysisData.ai_analysis.analysis || 'No analysis available'}
                
                ---
                `;
              }
              
              // Add recommendations
              if (analysisData.recommendations?.immediate_actions?.length > 0) {
                comment += `### 📦 Immediate Actions
                \`\`\`bash
                ${analysisData.recommendations.immediate_actions.slice(0, 5).join('\n')}
                \`\`\`
                
                ---
                `;
              }
              
              // Add long-term improvements
              if (analysisData.recommendations?.long_term_improvements?.length > 0) {
                comment += `### 🚀 Long-term Improvements
                ${analysisData.recommendations.long_term_improvements.map(imp => `- ${imp}`).join('\n')}
                
                ---
                `;
              }
              
              // Add workflow changes
              if (analysisData.recommendations?.workflow_changes?.length > 0) {
                comment += `### ⚙️ Workflow Changes
                ${analysisData.recommendations.workflow_changes.map(change => `- ${change}`).join('\n')}
                
                ---
                `;
              }
            } else {
              comment += `**ℹ️ Analysis Status:** No detailed analysis results available
              
              This could mean:
              - No dependency issues were detected
              - The AI analysis is still processing
              - There was an issue with the analysis script
              
              ---
              `;
            }
            
            comment += `
            ---
            
            *🤖 Generated by AI Dependency Resolver at ${new Date().toISOString()}*
            *Using 16-provider fallback system for maximum reliability*
            `;
            
            // Post comment to PR
            try {
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
              console.log('✅ PR comment posted successfully');
            } catch (error) {
              console.log('❌ Failed to post PR comment:', error.message);
              throw error;
            }

  summary:
    runs-on: ubuntu-latest
    needs: [dependency_analysis, auto_fix_application, pr_comment]
    if: always()
    timeout-minutes: 2
    
    steps:
      - name: 📊 Generate Workflow Summary
        run: |
          echo "## 🤖 AI Dependency Resolver Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Job | Status | Details |" >> $GITHUB_STEP_SUMMARY
          echo "|-----|--------|---------|" >> $GITHUB_STEP_SUMMARY
          echo "| 🔍 Dependency Analysis | ${{ needs.dependency_analysis.result }} | Issues: ${{ needs.dependency_analysis.outputs.issue_count || 0 }} |" >> $GITHUB_STEP_SUMMARY
          echo "| 🔧 Auto-Fix Application | ${{ needs.auto_fix_application.result }} | ${{ needs.auto_fix_application.result == 'success' && 'Applied' || 'Skipped/Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| 📝 PR Comment | ${{ needs.pr_comment.result }} | ${{ needs.pr_comment.result == 'success' && 'Posted' || 'Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**🎯 Result:** ${{ needs.dependency_analysis.result == 'success' && 'Dependencies analyzed and fixes applied' || 'Analysis failed - check logs' }}" >> $GITHUB_STEP_SUMMARY