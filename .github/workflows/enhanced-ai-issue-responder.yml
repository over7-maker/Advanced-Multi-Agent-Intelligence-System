name: Enhanced AI Issue Responder v2.0

# Advanced GitHub Issues automation with intelligent processing
on:
  issues:
    types: [opened, edited, reopened, labeled]
  issue_comment:
    types: [created, edited]
  workflow_dispatch:
    inputs:
      issue_number:
        description: 'Issue number to respond to'
        required: true
        type: string
      force_reprocess:
        description: 'Force reprocessing even if cached'
        required: false
        type: boolean
        default: false

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '20'

jobs:
  enhanced-ai-issue-response:
    runs-on: ubuntu-latest
    
    # Enhanced conditions with better filtering
    if: |
      (github.event.issue.pull_request == null) &&
      (github.event_name != 'issue_comment' || 
       !contains(github.event.comment.body, 'Enhanced AI Issues Responder v2.0'))
    
    permissions:
      issues: write
      contents: read
      pull-requests: read
    
    # Add concurrency control to prevent duplicate processing
    concurrency:
      group: issue-responder-${{ github.event.issue.number || github.event.inputs.issue_number }}
      cancel-in-progress: false
    
    steps:
    - name: üöÄ Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: üêç Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: üì¶ Install dependencies with caching
      run: |      python -m ensurepip --upgrade
        python -m pip install --upgrade pippython -m ensurepip --upgrade


        python -m pip install --upgrade pip
        python -m pip install --upgrade setuptools wheel
        if [ -f requirements.txt ]; then
          python -m pip install -r requirements.txt
        fi
        python -m pip install openai requests aiohttp sqlite3 groq google-generativeai cerebras
    
    - name: üîß Setup enhanced environment
      run: |
        echo "Setting up enhanced AI responder environment..."
        mkdir -p /tmp/ai_responder_cache
        mkdir -p logs
        
        # Create performance monitoring directory
        mkdir -p performance_reports
        
        # Set up database permissions
        touch /tmp/issues_cache.db
        chmod 666 /tmp/issues_cache.db
    
    - name: üß† Enhanced AI Issue Analysis and Response
      id: ai_response
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
        CLAUDE_API_KEY: ${{ secrets.CLAUDE_API_KEY }}
        GPT4_API_KEY: ${{ secrets.GPT4_API_KEY }}
        GLM_API_KEY: ${{ secrets.GLM_API_KEY }}
        GROK_API_KEY: ${{ secrets.GROK_API_KEY }}
        KIMI_API_KEY: ${{ secrets.KIMI_API_KEY }}
        QWEN_API_KEY: ${{ secrets.QWEN_API_KEY }}
        GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        GPTOSS_API_KEY: ${{ secrets.GPTOSS_API_KEY }}
        GROQAI_API_KEY: ${{ secrets.GROQAI_API_KEY }}
        CEREBRAS_API_KEY: ${{ secrets.CEREBRAS_API_KEY }}
        GEMINIAI_API_KEY: ${{ secrets.GEMINIAI_API_KEY }}
        ISSUE_NUMBER: ${{ github.event.issue.number || github.event.inputs.issue_number }}
        ISSUE_TITLE: ${{ github.event.issue.title }}
        ISSUE_BODY: ${{ github.event.issue.body }}
        ISSUE_AUTHOR: ${{ github.event.issue.user.login }}
        REPO_NAME: ${{ github.repository }}
        ACTION: ${{ github.event.action }}
        FORCE_REPROCESS: ${{ github.event.inputs.force_reprocess }}
      run: |
        echo "üöÄ Starting Enhanced AI Issue Processing..."
        echo "Issue Number: $ISSUE_NUMBER"
        echo "Issue Title: $ISSUE_TITLE"
        echo "Issue Author: $ISSUE_AUTHOR"
        echo "Repository: $REPO_NAME"
        echo "Action: $ACTION"
        echo ""
        
        # Run the enhanced AI issues responder
        python scripts/ai_issues_responder_v2.py \
          --issue-number "$ISSUE_NUMBER" \
          --issue-title "$ISSUE_TITLE" \
          --issue-body "$ISSUE_BODY" \
          --repository "$REPO_NAME" \
          --action "$ACTION" \
          --author "$ISSUE_AUTHOR" \
          --output "performance_reports/issue_${ISSUE_NUMBER}_response.json" \
          --verbose || {
            echo "‚ùå Enhanced processing failed, attempting fallback..."
            
            # Fallback to original responder if available
            if [ -f scripts/ai_issues_responder.py ]; then
              python scripts/ai_issues_responder.py \
                --issue-number "$ISSUE_NUMBER" \
                --issue-title "$ISSUE_TITLE" \
                --issue-body "$ISSUE_BODY" \
                --repository "$REPO_NAME" \
                --action "$ACTION" \
                --output "performance_reports/issue_${ISSUE_NUMBER}_fallback.json" || \
              echo "‚ö†Ô∏è Both enhanced and fallback processing failed"
            else
              echo "‚ö†Ô∏è No fallback responder available"
            fi
          }
        
        echo "‚úÖ Enhanced AI processing complete!"
    
    - name: üìä Generate Performance Report
      id: performance
      if: always()
      run: |
        echo "üìä Generating performance report..."
        
        # Generate performance report
        python scripts/ai_issues_responder_v2.py --performance-report > performance_reports/performance_report.json || \
        echo '{"error": "Performance report generation failed"}' > performance_reports/performance_report.json
        
        # Generate cache statistics
        python scripts/ai_issues_responder_v2.py --cache-stats > performance_reports/cache_stats.txt || \
        echo "Cache stats generation failed" > performance_reports/cache_stats.txt
        
        # Extract key metrics for GitHub output
        if [ -f "performance_reports/issue_${ISSUE_NUMBER}_response.json" ]; then
          PROCESSING_TIME=$(jq -r '.processing_time // 0' "performance_reports/issue_${ISSUE_NUMBER}_response.json")
          SUCCESS=$(jq -r '.success // false' "performance_reports/issue_${ISSUE_NUMBER}_response.json")
          CONFIDENCE=$(jq -r '.confidence // 0' "performance_reports/issue_${ISSUE_NUMBER}_response.json")
          LANGUAGE=$(jq -r '.language // "unknown"' "performance_reports/issue_${ISSUE_NUMBER}_response.json")
          ANALYSIS_PROVIDER=$(jq -r '.analysis_provider // "unknown"' "performance_reports/issue_${ISSUE_NUMBER}_response.json")
          RESPONSE_PROVIDER=$(jq -r '.response_provider // "unknown"' "performance_reports/issue_${ISSUE_NUMBER}_response.json")
          
          echo "processing_time=$PROCESSING_TIME" >> $GITHUB_OUTPUT
          echo "success=$SUCCESS" >> $GITHUB_OUTPUT
          echo "confidence=$CONFIDENCE" >> $GITHUB_OUTPUT
          echo "language=$LANGUAGE" >> $GITHUB_OUTPUT
          echo "analysis_provider=$ANALYSIS_PROVIDER" >> $GITHUB_OUTPUT
          echo "response_provider=$RESPONSE_PROVIDER" >> $GITHUB_OUTPUT
        else
          echo "processing_time=0" >> $GITHUB_OUTPUT
          echo "success=false" >> $GITHUB_OUTPUT
          echo "confidence=0" >> $GITHUB_OUTPUT
          echo "language=unknown" >> $GITHUB_OUTPUT
          echo "analysis_provider=unknown" >> $GITHUB_OUTPUT
          echo "response_provider=unknown" >> $GITHUB_OUTPUT
        fi
    
    - name: üè∑Ô∏è Add Enhanced AI Analysis Labels
      uses: actions/github-script@v7
      if: steps.performance.outputs.success == 'true'
      with:
        script: |
          const issueNumber = context.issue.number || '${{ github.event.inputs.issue_number }}';
          const confidence = parseFloat('${{ steps.performance.outputs.confidence }}');
          const language = '${{ steps.performance.outputs.language }}';
          
          const labels = ['ai-analyzed-v2', 'auto-response-enhanced'];
          
          // Add confidence-based labels
          if (confidence > 0.8) {
            labels.push('high-confidence');
          } else if (confidence > 0.6) {
            labels.push('medium-confidence');
          } else {
            labels.push('low-confidence');
          }
          
          // Add language label if not English
          if (language && language !== 'en' && language !== 'unknown') {
            labels.push(`lang:${language}`);
          }
          
          try {
            await github.rest.issues.addLabels({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              labels: labels
            });
            
            console.log(`‚úÖ Added enhanced labels: ${labels.join(', ')}`);
          } catch (error) {
            console.error(`‚ùå Failed to add labels: ${error.message}`);
          }
    
    - name: üìà Upload Performance Reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: enhanced-ai-performance-reports-${{ github.event.issue.number || github.event.inputs.issue_number }}
        path: performance_reports/
        retention-days: 30
    
    - name: üíæ Upload Cache Database
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: ai-responder-cache-${{ github.run_number }}
        path: /tmp/issues_cache.db
        retention-days: 7
    
    - name: üìã Generate Enhanced Response Summary
      id: summary
      if: always()
      run: |
        echo "## ü§ñ Enhanced AI Issue Response Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### üìä Processing Results" >> $GITHUB_STEP_SUMMARY
        echo "- **Issue Number**: #${{ github.event.issue.number || github.event.inputs.issue_number }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Issue Title**: ${{ github.event.issue.title }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Issue Author**: ${{ github.event.issue.user.login }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Processing Success**: ${{ steps.performance.outputs.success }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Processing Time**: ${{ steps.performance.outputs.processing_time }}s" >> $GITHUB_STEP_SUMMARY
        echo "- **Confidence Score**: ${{ steps.performance.outputs.confidence }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Detected Language**: ${{ steps.performance.outputs.language }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ü§ñ AI Providers Used" >> $GITHUB_STEP_SUMMARY
        echo "- **Analysis Provider**: ${{ steps.performance.outputs.analysis_provider }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Response Provider**: ${{ steps.performance.outputs.response_provider }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ‚ö° System Status" >> $GITHUB_STEP_SUMMARY
        echo "- **Responder Version**: v2.0 Enhanced" >> $GITHUB_STEP_SUMMARY
        echo "- **Fallback System**: ‚úÖ 9-Provider Intelligent Fallback" >> $GITHUB_STEP_SUMMARY
        echo "- **Caching**: ‚úÖ SQLite-based Performance Caching" >> $GITHUB_STEP_SUMMARY
        echo "- **Multi-language**: ‚úÖ Automatic Language Detection" >> $GITHUB_STEP_SUMMARY
        echo "- **Smart Labels**: ‚úÖ Context-aware Label Suggestions" >> $GITHUB_STEP_SUMMARY
        echo "- **Follow-up Scheduling**: ‚úÖ Automated Follow-up Management" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### üîó Artifacts" >> $GITHUB_STEP_SUMMARY
        echo "- Performance reports and cache database uploaded as artifacts" >> $GITHUB_STEP_SUMMARY
        echo "- Detailed logs available in workflow run" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "---" >> $GITHUB_STEP_SUMMARY
        echo "*Enhanced AI Issue Responder v2.0 - Powered by Advanced Multi-Agent AI System*" >> $GITHUB_STEP_SUMMARY
    
    - name: üö® Notify on Failure
      uses: actions/github-script@v7
      if: failure()
      with:
        script: |
          const issueNumber = context.issue.number || '${{ github.event.inputs.issue_number }}';
          
          const failureComment = `## ‚ö†Ô∏è Enhanced AI Response System Notice
          
I encountered an issue while processing this GitHub issue with the Enhanced AI Responder v2.0. 

**What happened:**
- The enhanced AI analysis system experienced a temporary issue
- This might be due to high load on AI providers or a temporary service disruption
- Your issue is still important and will be reviewed by our team

**Next steps:**
- Our team has been notified of this issue
- A human team member will review your issue shortly
- You can expect a response within 24 hours

**For urgent issues:**
- Please add the \`urgent\` label to your issue
- Consider reaching out through our other support channels

Thank you for your patience! üôè

---
*Enhanced AI Issue Responder v2.0 - Failure Notification*`;

          try {
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              body: failureComment
            });
            
            console.log('‚úÖ Failure notification comment posted');
          } catch (error) {
            console.error(`‚ùå Failed to post failure notification: ${error.message}`);
          }

  # Separate job for follow-up processing
  follow-up-processor:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'
    
    steps:
    - name: üöÄ Checkout repository
      uses: actions/checkout@v4
    
    - name: üêç Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: üìÖ Process Scheduled Follow-ups
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        echo "üìÖ Processing scheduled follow-ups..."
        # This would be implemented as a separate script
        # python scripts/process_followups.py
        echo "Follow-up processing would be implemented here"
    
  # Health check job
  system-health-check:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'
    
    steps:
    - name: üöÄ Checkout repository
      uses: actions/checkout@v4
    
    - name: üêç Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: üîç AI Providers Health Check
      env:
        DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
        GLM_API_KEY: ${{ secrets.GLM_API_KEY }}
        GROK_API_KEY: ${{ secrets.GROK_API_KEY }}
        KIMI_API_KEY: ${{ secrets.KIMI_API_KEY }}
        QWEN_API_KEY: ${{ secrets.QWEN_API_KEY }}
        GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        GPTOSS_API_KEY: ${{ secrets.GPTOSS_API_KEY }}
        GROQAI_API_KEY: ${{ secrets.GROQAI_API_KEY }}
        CEREBRAS_API_KEY: ${{ secrets.CEREBRAS_API_KEY }}
        GEMINIAI_API_KEY: ${{ secrets.GEMINIAI_API_KEY }}
      run: |
        echo "üîç Checking AI provider health..."
        python -c "
        import sys
        sys.path.append('services')
        from ultimate_fallback_system import get_provider_health, get_fallback_stats
        
        health = get_provider_health()
        stats = get_fallback_stats()
        
        print('üè• Provider Health Status:')
        for provider, info in health.items():
            status_emoji = '‚úÖ' if info['status'] == 'active' else '‚ùå'
            print(f'  {status_emoji} {info[\"name\"]}: {info[\"status\"]}')
        
        active_count = sum(1 for info in health.values() if info['status'] == 'active')
        print(f'\nüìä System Stats:')
        print(f'  Active Providers: {active_count}/9')
        print(f'  Total Requests: {stats.get(\"total_requests\", 0)}')
        print(f'  Success Rate: {stats.get(\"successful_requests\", 0) / max(stats.get(\"total_requests\", 1), 1) * 100:.1f}%')
        "