#!/usr/bin/env python3
"""
Unified REAL AI Manager for AMAS - NO FAKE RESPONSES ALLOWED
This script enforces actual API calls to real AI providers and validates responses
"""

import os
import asyncio
import aiohttp
import json
import time
import sys
from datetime import datetime
from typing import Dict, Any, List, Optional

class UnifiedRealAIManager:
    """REAL AI manager that enforces actual API calls to 16 providers"""
    
    def __init__(self):
        self.providers = self._load_real_providers()
        self.session = None
        
        # Validate we have real providers
        active_providers = [p for p in self.providers if p["api_key"]]
        print(f"🔍 REAL AI VALIDATION: {len(active_providers)}/16 providers available")
        
        if len(active_providers) == 0:
            raise Exception("❌ NO REAL AI PROVIDERS AVAILABLE - Check API keys!")
    
    def _load_real_providers(self) -> List[Dict[str, Any]]:
        """Load all 16 REAL AI providers with actual API keys"""
        return [
            {
                "name": "deepseek",
                "api_key": os.environ.get("DEEPSEEK_API_KEY"),
                "base_url": "https://openrouter.ai/api/v1",
                "model": "deepseek/deepseek-chat-v3.1:free",
                "priority": 1,
                "type": "openrouter"
            },
            {
                "name": "cerebras", 
                "api_key": os.environ.get("CEREBRAS_API_KEY"),
                "base_url": "https://api.cerebras.ai/v1",
                "model": "qwen-3-235b-a22b-instruct-2507",
                "priority": 1,
                "type": "cerebras"
            },
            {
                "name": "nvidia",
                "api_key": os.environ.get("NVIDIA_API_KEY"),
                "base_url": "https://integrate.api.nvidia.com/v1", 
                "model": "deepseek-ai/deepseek-r1",
                "priority": 1,
                "type": "nvidia"
            },
            {
                "name": "codestral",
                "api_key": os.environ.get("CODESTRAL_API_KEY"),
                "base_url": "https://codestral.mistral.ai/v1",
                "model": "codestral-latest", 
                "priority": 2,
                "type": "codestral"
            },
            {
                "name": "glm",
                "api_key": os.environ.get("GLM_API_KEY"),
                "base_url": "https://openrouter.ai/api/v1",
                "model": "z-ai/glm-4.5-air:free",
                "priority": 2,
                "type": "openrouter"
            },
            {
                "name": "grok",
                "api_key": os.environ.get("GROK_API_KEY"),
                "base_url": "https://openrouter.ai/api/v1",
                "model": "x-ai/grok-4-fast:free",
                "priority": 2,
                "type": "openrouter"
            },
            {
                "name": "kimi",
                "api_key": os.environ.get("KIMI_API_KEY"),
                "base_url": "https://openrouter.ai/api/v1",
                "model": "moonshot/moonshot-v1-8k:free",
                "priority": 3,
                "type": "openrouter"
            },
            {
                "name": "qwen",
                "api_key": os.environ.get("QWEN_API_KEY"),
                "base_url": "https://openrouter.ai/api/v1",
                "model": "qwen/qwen-2.5-72b-instruct:free",
                "priority": 3,
                "type": "openrouter"
            },
            {
                "name": "gemini",
                "api_key": os.environ.get("GEMINI_API_KEY"),
                "base_url": "https://generativelanguage.googleapis.com/v1beta",
                "model": "gemini-1.5-flash",
                "priority": 4,
                "type": "gemini"
            },
            {
                "name": "gptoss",
                "api_key": os.environ.get("GPTOSS_API_KEY"),
                "base_url": "https://openrouter.ai/api/v1",
                "model": "gptoss/gptoss-7b:free",
                "priority": 4,
                "type": "openrouter"
            },
            {
                "name": "claude",
                "api_key": os.environ.get("CLAUDE_API_KEY"),
                "base_url": "https://api.anthropic.com/v1",
                "model": "claude-3-haiku-20240307",
                "priority": 5,
                "type": "claude"
            },
            {
                "name": "openai",
                "api_key": os.environ.get("OPENAI_API_KEY"),
                "base_url": "https://api.openai.com/v1",
                "model": "gpt-3.5-turbo",
                "priority": 5,
                "type": "openai"
            },
            {
                "name": "cohere",
                "api_key": os.environ.get("COHERE_API_KEY"),
                "base_url": "https://api.cohere.ai/v1",
                "model": "command",
                "priority": 6,
                "type": "cohere"
            },
            {
                "name": "mistral",
                "api_key": os.environ.get("MISTRAL_API_KEY"),
                "base_url": "https://api.mistral.ai/v1",
                "model": "mistral-tiny",
                "priority": 6,
                "type": "mistral"
            },
            {
                "name": "perplexity",
                "api_key": os.environ.get("PERPLEXITY_API_KEY"),
                "base_url": "https://api.perplexity.ai",
                "model": "llama-3.1-sonar-small-128k-online",
                "priority": 7,
                "type": "perplexity"
            },
            {
                "name": "groq",
                "api_key": os.environ.get("GROQ_API_KEY"),
                "base_url": "https://api.groq.com/openai/v1",
                "model": "llama3-8b-8192",
                "priority": 7,
                "type": "groq"
            }
        ]
    
    async def perform_real_analysis(self, task_type: str, content: str) -> Dict[str, Any]:
        """
        Perform REAL AI analysis - NO FAKE RESPONSES ALLOWED
        """
        if not self.session:
            self.session = aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=30))
        
        print(f"🤖 STARTING REAL AI ANALYSIS: {task_type}")
        
        # Sort by priority and try each provider
        sorted_providers = sorted([p for p in self.providers if p["api_key"]], key=lambda x: x["priority"])
        
        for attempt, provider in enumerate(sorted_providers, 1):
            try:
                print(f"🔄 Attempt {attempt}: Trying {provider['name']}")
                start_time = time.time()
                
                response = await self._make_real_api_call(provider, task_type, content)
                response_time = time.time() - start_time
                
                # Validate response is not generic/fake
                if self._validate_real_response(response):
                    print(f"✅ REAL AI SUCCESS: {provider['name']} in {response_time:.2f}s")
                    
                    return {
                        "success": True,
                        "provider": provider["name"],
                        "response_time": round(response_time, 2),
                        "analysis": response,
                        "task_type": task_type,
                        "timestamp": datetime.utcnow().isoformat(),
                        "real_ai_verified": True,  # CRITICAL FLAG
                        "attempt_number": attempt,
                        "total_providers_available": len(sorted_providers)
                    }
                else:
                    print(f"❌ FAKE RESPONSE DETECTED from {provider['name']}")
                    continue
                    
            except Exception as e:
                print(f"❌ Provider {provider['name']} failed: {str(e)}")
                continue
        
        # All providers failed
        raise Exception("🚨 ALL REAL AI PROVIDERS FAILED - Cannot generate fake response!")
    
    def _validate_real_response(self, response: str) -> bool:
        """Validate response is from real AI, not fake template"""
        fake_indicators = [
            "AI-powered analysis completed successfully",
            "Continue current practices", 
            "All checks passed",
            "No analysis available",
            "Add comprehensive error handling",
            "Implement unit tests for new features",
            "Code quality score: 8.5/10"
        ]
        
        # Check if response is too generic
        for fake_phrase in fake_indicators:
            if fake_phrase.lower() in response.lower():
                return False
        
        # Must be substantial and specific
        if len(response) < 100:
            return False
            
        # Must contain specific technical details
        technical_indicators = ["line", "file", "function", "class", "import", "def", "async", "await"]
        if not any(indicator in response.lower() for indicator in technical_indicators):
            return False
            
        return True
    
    async def _make_real_api_call(self, provider: Dict[str, Any], task_type: str, content: str) -> str:
        """Make actual API call to real AI provider"""
        
        # Create specific prompt for task type
        prompts = {
            "code_quality": f"""
Analyze this code for quality issues. Be SPECIFIC with file names and line numbers:

{content[:2000]}

Provide specific recommendations with exact locations, not generic advice.
""",
            "security": f"""
Perform security analysis of this code. Find actual vulnerabilities:

{content[:2000]}

List specific security issues with file names, line numbers, and severity levels.
""",
            "performance": f"""
Analyze performance bottlenecks in this code:

{content[:2000]}

Identify specific performance issues with file locations and optimization suggestions.
""",
            "dependency_analysis": f"""
Analyze dependencies and potential conflicts in this code:

{content[:2000]}

Identify specific dependency issues with exact package names and versions.
""",
            "build_analysis": f"""
Analyze build configuration and potential issues:

{content[:2000]}

Identify specific build problems with exact configuration details.
"""
        }
        
        prompt = prompts.get(task_type, f"Analyze this {task_type}: {content[:2000]}")
        
        headers = {"Authorization": f"Bearer {provider['api_key']}", "Content-Type": "application/json"}
        
        # Handle different provider types
        if provider["type"] == "openrouter":
            headers["HTTP-Referer"] = "https://github.com/over7-maker/Advanced-Multi-Agent-Intelligence-System"
            headers["X-Title"] = "AMAS Real AI System"
        elif provider["type"] == "claude":
            headers["anthropic-version"] = "2023-06-01"
        elif provider["type"] == "gemini":
            headers["x-goog-api-key"] = provider["api_key"]
            del headers["Authorization"]
        
        # Create provider-specific payload
        if provider["type"] == "claude":
            payload = {
                "model": provider["model"],
                "max_tokens": 1500,
                "messages": [
                    {"role": "user", "content": f"You are an expert {task_type} analyst. Provide specific, detailed analysis with exact file names and line numbers. Avoid generic responses.\n\n{prompt}"}
                ]
            }
        elif provider["type"] == "gemini":
            payload = {
                "contents": [{
                    "parts": [{
                        "text": f"You are an expert {task_type} analyst. Provide specific, detailed analysis with exact file names and line numbers. Avoid generic responses.\n\n{prompt}"
                    }]
                }],
                "generationConfig": {
                    "temperature": 0.7,
                    "maxOutputTokens": 1500
                }
            }
        elif provider["type"] == "cohere":
            payload = {
                "model": provider["model"],
                "message": f"You are an expert {task_type} analyst. Provide specific, detailed analysis with exact file names and line numbers. Avoid generic responses.\n\n{prompt}",
                "max_tokens": 1500,
                "temperature": 0.7
            }
        else:  # OpenAI-compatible
            payload = {
                "model": provider["model"],
                "messages": [
                    {"role": "system", "content": f"You are an expert {task_type} analyst. Provide specific, detailed analysis with exact file names and line numbers. Avoid generic responses."},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.7,
                "max_tokens": 1500
            }
        
        # Make the API call
        if provider["type"] == "gemini":
            url = f"{provider['base_url']}/models/{provider['model']}:generateContent"
        elif provider["type"] == "cohere":
            url = f"{provider['base_url']}/chat"
        else:
            url = f"{provider['base_url']}/chat/completions"
        
        async with self.session.post(url, headers=headers, json=payload) as response:
            if response.status == 200:
                data = await response.json()
                
                # Extract response based on provider type
                if provider["type"] == "claude":
                    return data["content"][0]["text"]
                elif provider["type"] == "gemini":
                    return data["candidates"][0]["content"]["parts"][0]["text"]
                elif provider["type"] == "cohere":
                    return data["message"]
                else:  # OpenAI-compatible
                    return data["choices"][0]["message"]["content"]
            else:
                error_text = await response.text()
                raise Exception(f"HTTP {response.status}: {error_text}")

# Main function for workflow integration
async def main():
    """Main entry point for REAL AI analysis"""
    
    if len(sys.argv) < 2:
        task_type = "code_quality"
    else:
        task_type = sys.argv[1]
    
    try:
        # Initialize REAL AI manager
        ai_manager = UnifiedRealAIManager()
        
        # Get content to analyze (from PR changes or file)
        content = "# Code content from PR changes"
        if len(sys.argv) > 2:
            file_path = sys.argv[2]
            try:
                with open(file_path, 'r') as f:
                    content = f.read()
            except FileNotFoundError:
                print(f"⚠️ File not found: {file_path}, using default content")
        
        # Perform REAL analysis
        result = await ai_manager.perform_real_analysis(task_type, content)
        
        # Save results with validation
        os.makedirs("artifacts", exist_ok=True)
        with open(f"artifacts/real_{task_type}_analysis.json", "w") as f:
            json.dump(result, f, indent=2)
        
        # Validate it's REAL AI
        if result["real_ai_verified"]:
            print(f"✅ REAL AI ANALYSIS VERIFIED!")
            print(f"🤖 Provider: {result['provider']}")
            print(f"⏱️ Response Time: {result['response_time']}s") 
            print(f"🔄 Attempt: {result['attempt_number']}/{result['total_providers_available']}")
        else:
            print("❌ FAKE AI DETECTED!")
            sys.exit(1)
            
    except Exception as e:
        print(f"❌ REAL AI ANALYSIS FAILED: {str(e)}")
        sys.exit(1)
    finally:
        if ai_manager.session:
            await ai_manager.session.close()

if __name__ == "__main__":
    asyncio.run(main())