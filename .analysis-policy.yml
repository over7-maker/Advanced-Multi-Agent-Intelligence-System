# AMAS Bulletproof AI Analysis Policy Configuration
# This configuration controls AI-powered code analysis behavior and quality gates
schema_version: 1

# Cap diff-only findings to 0.4 to avoid overconfidence on partial context
# Full-file analyses are un-capped by policy and used for blocker decisions

# Confidence thresholds for AI findings
# These values determine when AI analysis results in different action types
confidence_thresholds:
  blocker: 0.8    # High confidence required to block PRs
  warning: 0.6    # Medium confidence for warnings
  info: 0.0       # All findings shown as informational

# Policy gates - Core behavioral controls
policy:
  # Require complete file context before making blocking decisions
  require_full_context_for_blockers: true
  
  # Prevent AI from making syntax-level assertions when deterministic analysis (e.g., linter) already confirmed correctness
  # This avoids redundant "syntax error" claims when py_compile already validated the code
  forbid_syntax_claims_when_deterministic_ok: true
  
  # Limit AI confidence on diff-only analysis to prevent overreliance on partial context
  # This ensures AI doesn't make high-confidence claims without seeing full file structure
  diff_only_caps_confidence: 0.4

# Suppress noisy analysis categories that provide little value
suppress:
  - truncated-diff-syntax      # Don't complain about syntax in truncated diffs
  - long-collection-truncation  # Expected behavior for large collections

# File-specific analysis rules
# These rules customize analysis behavior for specific files or patterns
rules:
  # Critical bulletproof analyzer requires comprehensive analysis
  - paths:
      - ".github/scripts/bulletproof_ai_pr_analyzer.py"
    require_full_file_analysis: true    # Always analyze complete file, not just diff
    enforce_deterministic_first: true   # Run deterministic checks (py_compile, linting) before AI analysis
    
  # Enhanced code review script needs import validation
  - paths:
      - ".github/scripts/ai_enhanced_code_review.py"
    require_full_file_analysis: true
    check_import_errors: true
    
  # AI issue responder needs security validation
  - paths:
      - ".github/scripts/ai_issue_responder.py"
    check_api_key_exposure: true
    validate_error_handling: true

# Artifact generation settings
# Control what files are generated during analysis for audit trails
artifacts:
  write_receipts: true              # Generate validation receipts for successful analyses
  upload_validation_receipt: true   # Upload receipts to GitHub Actions artifacts
