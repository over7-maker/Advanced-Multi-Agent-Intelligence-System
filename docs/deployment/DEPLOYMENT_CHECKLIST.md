# üöÄ Universal AI Manager - Deployment Checklist

Use this checklist to deploy the Universal AI Manager to your GitHub repository.

---

## Phase 1: Configuration ‚öôÔ∏è

### Step 1.1: Add Repository Secrets

Go to: **Settings ‚Üí Secrets and variables ‚Üí Actions ‚Üí New repository secret**

Add all 16 API keys:

- [ ] `DEEPSEEK_API_KEY` - DeepSeek V3.1
- [ ] `GLM_API_KEY` - GLM 4.5 Air
- [ ] `GROK_API_KEY` - xAI Grok
- [ ] `KIMI_API_KEY` - MoonshotAI Kimi
- [ ] `QWEN_API_KEY` - Qwen Plus
- [ ] `GPTOSS_API_KEY` - GPT OSS
- [ ] `GROQAI_API_KEY` - Groq AI (primary)
- [ ] `CEREBRAS_API_KEY` - Cerebras AI
- [ ] `GEMINIAI_API_KEY` - Gemini AI (primary)
- [ ] `CODESTRAL_API_KEY` - Codestral
- [ ] `NVIDIA_API_KEY` - NVIDIA AI
- [ ] `GEMINI2_API_KEY` - Gemini 2 (backup)
- [ ] `GROQ2_API_KEY` - Groq 2 (backup)
- [ ] `COHERE_API_KEY` - Cohere
- [ ] `CHUTES_API_KEY` - Chutes AI

**API Key Sources:**
- DeepSeek: `https://platform.deepseek.com`
- GLM: `https://open.bigmodel.cn`
- Grok: `https://console.x.ai` or via OpenRouter
- Kimi: `https://platform.moonshot.cn`
- Qwen: `https://dashscope.console.aliyun.com`
- Groq: `https://console.groq.com`
- Cerebras: `https://inference.cerebras.ai`
- Gemini: `https://aistudio.google.com/apikey`
- Codestral: `https://console.mistral.ai`
- NVIDIA: `https://build.nvidia.com`
- Cohere: `https://dashboard.cohere.com`
- Chutes: `https://chutes.ai`

### Step 1.2: Verify Secrets

Run this GitHub Action to verify secrets are set:

```yaml
name: Verify API Keys
on: workflow_dispatch

jobs:
  verify:
    runs-on: ubuntu-latest
    env:
      DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
      GLM_API_KEY: ${{ secrets.GLM_API_KEY }}
      # ... all 16 keys
    steps:
      - run: |
          count=0
          [ ! -z "$DEEPSEEK_API_KEY" ] && ((count++)) || echo "‚ùå DEEPSEEK_API_KEY missing"
          [ ! -z "$GLM_API_KEY" ] && ((count++)) || echo "‚ùå GLM_API_KEY missing"
          # ... check all keys
          echo "‚úÖ $count/15 API keys configured"
```

- [ ] All API keys verified

---

## Phase 2: Testing üß™

### Step 2.1: Test Standalone Version

```bash
# In your repository
python3 standalone_universal_ai_manager.py
```

Expected output:
```
‚úÖ Initialized X/15 providers
‚úÖ Test PASSED - Manager initialized successfully
```

- [ ] Standalone version tested locally
- [ ] At least 5 providers configured
- [ ] No errors in initialization

### Step 2.2: Test Workflow

Trigger `.github/workflows/universal-ai-workflow.yml`:

- [ ] Workflow runs successfully
- [ ] Providers are detected
- [ ] AI generation works
- [ ] Statistics are displayed
- [ ] Provider health shown

### Step 2.3: Test Multi-Agent Orchestrator

```bash
python3 .github/scripts/universal_multi_agent_orchestrator.py \
  --topic "test cybersecurity analysis" \
  --strategy intelligent
```

- [ ] Multi-agent orchestrator runs
- [ ] All phases complete
- [ ] Report generated
- [ ] Statistics accurate

---

## Phase 3: Migration üîÑ

### Step 3.1: Identify Files to Migrate

Run the integration script:

```bash
python3 scripts/integrate_universal_ai_manager.py
```

This will:
- Find all Python files using AI APIs (48 files identified)
- Generate `UNIVERSAL_AI_MANAGER_GUIDE.md`
- Create `MIGRATION_TEMPLATE.py`

- [ ] Integration script executed
- [ ] AI files identified
- [ ] Guides generated

### Step 3.2: Update Workflow Files

For each workflow in `.github/workflows/`:

**Add to `env:` section:**
```yaml
env:
  # All 16 AI API Keys
  DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
  GLM_API_KEY: ${{ secrets.GLM_API_KEY }}
  GROK_API_KEY: ${{ secrets.GROK_API_KEY }}
  KIMI_API_KEY: ${{ secrets.KIMI_API_KEY }}
  QWEN_API_KEY: ${{ secrets.QWEN_API_KEY }}
  GPTOSS_API_KEY: ${{ secrets.GPTOSS_API_KEY }}
  GROQAI_API_KEY: ${{ secrets.GROQAI_API_KEY }}
  CEREBRAS_API_KEY: ${{ secrets.CEREBRAS_API_KEY }}
  GEMINIAI_API_KEY: ${{ secrets.GEMINIAI_API_KEY }}
  CODESTRAL_API_KEY: ${{ secrets.CODESTRAL_API_KEY }}
  NVIDIA_API_KEY: ${{ secrets.NVIDIA_API_KEY }}
  GEMINI2_API_KEY: ${{ secrets.GEMINI2_API_KEY }}
  GROQ2_API_KEY: ${{ secrets.GROQ2_API_KEY }}
  COHERE_API_KEY: ${{ secrets.COHERE_API_KEY }}
  CHUTES_API_KEY: ${{ secrets.CHUTES_API_KEY }}
```

Workflows to update:
- [ ] `ai-issue-responder.yml`
- [ ] `ai-master-orchestrator.yml`
- [ ] `ai-enhanced-code-review.yml`
- [ ] `ai-threat-intelligence.yml`
- [ ] `ai-incident-response.yml`
- [ ] `ai-osint-collection.yml`
- [ ] `ai-security-response.yml`
- [ ] `multi-agent-workflow.yml`
- [ ] Any other AI-powered workflows

### Step 3.3: Update Python Scripts

For each script in `.github/scripts/`:

**Old code:**
```python
from openai import OpenAI

client = OpenAI(
    base_url="https://api.deepseek.com/v1",
    api_key=os.getenv('DEEPSEEK_API_KEY')
)

try:
    response = client.chat.completions.create(...)
except:
    # Manual fallback
    pass
```

**New code:**
```python
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from standalone_universal_ai_manager import generate_ai_response

result = await generate_ai_response(
    prompt="Your prompt",
    strategy='intelligent'
)

if result['success']:
    content = result['content']
```

Scripts to update:
- [ ] `ai_issue_responder.py`
- [ ] `ai_master_orchestrator.py`
- [ ] `multi_agent_orchestrator.py`
- [ ] `ai_enhanced_code_review.py`
- [ ] `ai_threat_intelligence.py`
- [ ] `ai_incident_response.py`
- [ ] `ai_osint_collector.py`
- [ ] `ai_security_response.py`
- [ ] Other AI scripts as needed

---

## Phase 4: Deployment üö¢

### Step 4.1: Commit New Files

```bash
git add standalone_universal_ai_manager.py
git add src/amas/services/universal_ai_manager.py
git add .github/scripts/universal_multi_agent_orchestrator.py
git add .github/workflows/universal-ai-workflow.yml
git add UNIVERSAL_AI_SYSTEM_README.md
git add IMPLEMENTATION_SUMMARY.md
git add DEPLOYMENT_CHECKLIST.md

git commit -m "Add Universal AI Manager with 16-provider fallback system"
git push
```

- [ ] New files committed
- [ ] Pushed to repository

### Step 4.2: Update Existing Files

Commit migrated workflows and scripts:

```bash
git add .github/workflows/
git add .github/scripts/

git commit -m "Update workflows and scripts to use Universal AI Manager"
git push
```

- [ ] Updated files committed
- [ ] Pushed to repository

### Step 4.3: Test in CI/CD

Trigger workflows to test:

- [ ] `universal-ai-workflow.yml` - ‚úÖ Passes
- [ ] `ai-issue-responder.yml` - ‚úÖ Passes
- [ ] `ai-master-orchestrator.yml` - ‚úÖ Passes
- [ ] Other workflows - ‚úÖ Pass

---

## Phase 5: Monitoring üìä

### Step 5.1: Set Up Monitoring

Create a monitoring workflow:

```yaml
name: AI System Health Check
on:
  schedule:
    - cron: '0 */6 * * *'  # Every 6 hours
  workflow_dispatch:

jobs:
  health-check:
    runs-on: ubuntu-latest
    env:
      # All 16 API keys
      DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
      # ... etc
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Check System Health
        run: |
          python3 <<EOF
          import asyncio
          from standalone_universal_ai_manager import get_manager
          
          async def check():
              manager = get_manager()
              
              # Test generation
              result = await manager.generate("Health check test", strategy='intelligent')
              
              # Show stats
              stats = manager.get_stats()
              print(f"Success Rate: {stats['success_rate']}")
              print(f"Active Providers: {stats['active_providers']}")
              
              # Show health
              health = manager.get_provider_health()
              for pid, info in health.items():
                  if info['success_count'] > 0 or info['failure_count'] > 0:
                      print(f"{info['name']}: {info['status']} - {info['success_rate']}")
              
              # Alert if success rate < 95%
              if float(stats['success_rate'].rstrip('%')) < 95:
                  print("‚ö†Ô∏è WARNING: Success rate below 95%!")
                  exit(1)
          
          asyncio.run(check())
          EOF
```

- [ ] Monitoring workflow created
- [ ] Schedule configured
- [ ] Alerts working

### Step 5.2: Dashboard Setup

Create a status page showing:
- [ ] Total providers configured
- [ ] Active providers count
- [ ] Current success rate
- [ ] Average response time
- [ ] Failed providers (if any)

### Step 5.3: Alert Configuration

Set up alerts for:
- [ ] Success rate < 95%
- [ ] All providers failing
- [ ] Consecutive fallbacks > 10
- [ ] Average response time > 10s

---

## Phase 6: Documentation üìö

### Step 6.1: Update Project README

Add to main `README.md`:

```markdown
## ü§ñ AI System

This project uses the **Universal AI Manager** with 16 AI providers for maximum reliability.

### Features
- ‚úÖ 16 AI providers with automatic fallback
- ‚úÖ Zero workflow failures
- ‚úÖ Intelligent provider selection
- ‚úÖ Real-time health monitoring

### Documentation
- [Complete Guide](UNIVERSAL_AI_SYSTEM_README.md)
- [Implementation Summary](IMPLEMENTATION_SUMMARY.md)
- [Deployment Checklist](DEPLOYMENT_CHECKLIST.md)

### Quick Start
```python
from standalone_universal_ai_manager import generate_ai_response

result = await generate_ai_response(
    prompt="Your prompt",
    strategy='intelligent'
)
```
```

- [ ] README updated
- [ ] Links added to documentation

### Step 6.2: Create CHANGELOG Entry

Add to `CHANGELOG.md`:

```markdown
## [X.X.X] - 2025-10-03

### Added
- Universal AI Manager with 16-provider fallback system
- Automatic provider selection strategies (Priority, Intelligent, Round Robin, Fastest)
- Circuit breaker pattern for failing providers
- Rate limit handling with automatic cooldown
- Comprehensive health monitoring and statistics
- Multi-agent orchestrator with universal fallback
- Complete documentation and migration guides

### Changed
- Updated all AI-powered workflows to use Universal AI Manager
- Migrated scripts to use centralized AI management
- Enhanced reliability with 16 providers instead of 6

### Fixed
- Eliminated workflow failures due to AI API issues
- Improved response time with intelligent provider selection
```

- [ ] CHANGELOG updated

---

## Phase 7: Validation ‚úÖ

### Step 7.1: End-to-End Testing

Test complete workflow:

1. [ ] Create a GitHub issue
2. [ ] AI issue responder triggers
3. [ ] Uses Universal AI Manager
4. [ ] Successfully generates response
5. [ ] Posts comment to issue
6. [ ] No errors in logs

### Step 7.2: Performance Testing

Run load test:

```python
import asyncio
from standalone_universal_ai_manager import get_manager

async def load_test():
    manager = get_manager()
    
    # 100 concurrent requests
    tasks = [
        manager.generate(f"Test {i}", strategy='round_robin')
        for i in range(100)
    ]
    
    results = await asyncio.gather(*tasks)
    
    successes = sum(1 for r in results if r['success'])
    print(f"Success rate: {successes}/100 = {successes}%")

asyncio.run(load_test())
```

- [ ] Load test completed
- [ ] Success rate > 95%
- [ ] No cascading failures

### Step 7.3: Failover Testing

Test failover by:

1. [ ] Remove API key for primary provider
2. [ ] Trigger workflow
3. [ ] Verify automatic fallback to secondary
4. [ ] Check logs show provider switch
5. [ ] Response still successful

---

## Phase 8: Optimization üéØ

### Step 8.1: Provider Priority Tuning

Based on performance data, adjust priorities:

```python
# In standalone_universal_ai_manager.py
# Reorder providers based on:
# - Response time
# - Success rate
# - Cost efficiency
# - Rate limits
```

- [ ] Performance data analyzed
- [ ] Priorities optimized
- [ ] Changes tested

### Step 8.2: Strategy Selection

Choose optimal strategy for each use case:

- **Issue Responder** ‚Üí `intelligent` (balanced)
- **Code Review** ‚Üí `fastest` (quick feedback)
- **Threat Analysis** ‚Üí `priority` (consistent results)
- **Load Distribution** ‚Üí `round_robin` (even load)

- [ ] Strategies assigned per use case
- [ ] Documented in code comments

### Step 8.3: Cost Optimization

Track usage per provider:

```python
stats = manager.get_stats()
print(stats['providers_usage'])

# Prioritize free tiers
# Distribute load to avoid rate limits
```

- [ ] Usage tracked
- [ ] Free tiers maximized
- [ ] Load distributed efficiently

---

## Phase 9: Maintenance üîß

### Step 9.1: Regular Health Checks

Schedule:
- [ ] Daily: Check provider health
- [ ] Weekly: Review statistics
- [ ] Monthly: Analyze trends

### Step 9.2: Provider Updates

Monitor for:
- [ ] New API versions
- [ ] Model updates
- [ ] Endpoint changes
- [ ] Rate limit changes

### Step 9.3: Documentation Updates

Keep updated:
- [ ] Provider list
- [ ] API endpoints
- [ ] Configuration examples
- [ ] Troubleshooting guides

---

## Success Criteria ‚ú®

Your deployment is successful when:

- ‚úÖ All 16 API keys configured
- ‚úÖ At least 10 providers active
- ‚úÖ Workflows using Universal AI Manager
- ‚úÖ Success rate > 95%
- ‚úÖ Average response time < 5s
- ‚úÖ No workflow failures in 1 week
- ‚úÖ Monitoring in place
- ‚úÖ Documentation complete

---

## Rollback Plan üîÑ

If issues occur:

1. **Immediate**: Revert to previous workflow versions
   ```bash
   git revert <commit-hash>
   git push
   ```

2. **Temporary**: Use single provider
   ```python
   # Force specific provider
   result = await manager.generate(prompt, strategy='priority', max_attempts=1)
   ```

3. **Investigation**: Check logs and provider health
   ```python
   health = manager.get_provider_health()
   # Identify failing providers
   ```

---

## Support & Resources üìû

### Documentation
- **Complete Guide**: `UNIVERSAL_AI_SYSTEM_README.md`
- **Implementation**: `IMPLEMENTATION_SUMMARY.md`
- **Migration**: `MIGRATION_TEMPLATE.py`

### Testing
```bash
# Test standalone
python3 standalone_universal_ai_manager.py

# Test multi-agent
python3 .github/scripts/universal_multi_agent_orchestrator.py --topic "test"

# Test workflow
# Trigger .github/workflows/universal-ai-workflow.yml
```

### Troubleshooting
See "Troubleshooting" section in `UNIVERSAL_AI_SYSTEM_README.md`

---

## Completion ‚úÖ

**Deployment Complete!** üéâ

Your AI system now has:
- ‚úÖ 16-provider fallback for zero failures
- ‚úÖ Intelligent routing for optimal performance
- ‚úÖ Health monitoring and statistics
- ‚úÖ Production-ready workflows
- ‚úÖ Comprehensive documentation

**Next**: Monitor performance and enjoy 99.9%+ reliability! üöÄ

---

**Last Updated**: October 3, 2025  
**Version**: 1.0.0  
**Status**: Ready for Production
