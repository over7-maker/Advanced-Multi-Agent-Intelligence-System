# AMAS Environment Configuration
# Copy this file to .env and add your API keys

# =============================================================================
# MINIMAL SETUP (Required for basic functionality)
# =============================================================================
# You need at least 2-3 of these providers for basic operation:

# OpenAI (Recommended - High quality, reliable)
OPENAI_API_KEY=your_openai_api_key_here

# Google Gemini (Recommended - Fast, free tier available)
GEMINIAI_API_KEY=your_gemini_api_key_here

# Groq (Recommended - Very fast, free tier available)
GROQAI_API_KEY=your_groq_api_key_here

# =============================================================================
# EXTENDED SETUP (Optional for redundancy and load balancing)
# =============================================================================
# Add these for higher redundancy and better performance:

# Cohere (Good for specific tasks)
COHERE_API_KEY=your_cohere_api_key_here

# Anthropic Claude (High quality, good for complex tasks)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Hugging Face (Open source models)
HUGGINGFACE_API_KEY=your_huggingface_api_key_here

# NVIDIA AI (GPU-accelerated inference)
NVIDIAAI_API_KEY=your_nvidia_api_key_here

# Replicate (Various open source models)
REPLICATE_API_KEY=your_replicate_api_key_here

# Together AI (Open source models)
TOGETHERAI_API_KEY=your_together_api_key_here

# Perplexity (Good for research tasks)
PERPLEXITY_API_KEY=your_perplexity_api_key_here

# DeepSeek (Cost-effective alternative)
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# Mistral AI (European alternative)
MISTRALAI_API_KEY=your_mistral_api_key_here

# =============================================================================
# LOCAL/SELF-HOSTED OPTIONS (Advanced users)
# =============================================================================

# Ollama (Local models)
OLLAMA_API_KEY=your_ollama_api_key_here
OLLAMA_BASE_URL=http://localhost:11434

# LocalAI (Self-hosted OpenAI-compatible)
LOCALAI_API_KEY=your_localai_api_key_here
LOCALAI_BASE_URL=http://localhost:8080

# Custom provider
CUSTOM_API_KEY=your_custom_api_key_here
CUSTOM_BASE_URL=http://your-custom-endpoint.com

# =============================================================================
# SYSTEM CONFIGURATION
# =============================================================================

# Database URLs (Optional - for persistent storage)
DATABASE_URL=sqlite:///data/amas.db
REDIS_URL=redis://localhost:6379/0
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_neo4j_password

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/amas.log

# Security
JWT_SECRET=your_jwt_secret_here
ENCRYPTION_KEY=your_encryption_key_here

# Performance
MAX_CONCURRENT_REQUESTS=10
REQUEST_TIMEOUT=30
CACHE_TTL=3600

# =============================================================================
# QUICK START GUIDE
# =============================================================================
# 1. Copy this file: cp .env.example .env
# 2. Add at least 2-3 API keys from the "MINIMAL SETUP" section above
# 3. Run validation: python scripts/validate_env.py
# 4. Start AMAS: python -m amas
#
# For more providers, add keys from the "EXTENDED SETUP" section
# More providers = better redundancy and performance!